#!/usr/bin/env python3
"""
æµ‹è¯•æ•°æ®åˆ†å‰²ä¿®å¤çš„è„šæœ¬
"""

import os
import sys
import logging
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
current_path = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_path)

def setup_test_logging():
    """è®¾ç½®æµ‹è¯•æ—¥å¿—"""
    formatter = logging.Formatter(
        '%(asctime)s | %(levelname)8s | %(name)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    console_handler.setLevel(logging.INFO)
    
    logging.basicConfig(
        level=logging.INFO,
        handlers=[console_handler],
        force=True
    )

def test_data_segment_fix():
    """æµ‹è¯•DataSegmentä¿®å¤"""
    print("=" * 60)
    print("æµ‹è¯• DataSegment ä¿®å¤")
    print("=" * 60)
    
    try:
        # ä½¿ç”¨ä¿®å¤åçš„DataSegment
        from src.data.DataSegment import DataSegment
        
        segmenter = DataSegment(chunk_size=100000, n_processes=2)
        print("âœ“ DataSegment_Fixed å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•åŸºæœ¬æ–¹æ³•
        pattern = segmenter._get_segment_pattern(1)
        print(f"âœ“ _get_segment_pattern(1) = '{pattern}'")
        
        # æ£€æŸ¥å…³é”®æ–¹æ³•æ˜¯å¦å­˜åœ¨
        required_methods = [
            '_get_ranker_segment_classification',
            'process_file',
            'verify_segmentation',
            'get_output_files'
        ]
        
        for method in required_methods:
            if hasattr(segmenter, method):
                print(f"âœ“ æ–¹æ³• {method} å­˜åœ¨")
            else:
                print(f"âœ— æ–¹æ³• {method} ç¼ºå¤±")
                return False
        
        return True
        
    except Exception as e:
        print(f"âœ— DataSegment æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_data_processor_fix():
    """æµ‹è¯•DataProcessorä¿®å¤"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• DataProcessor ä¿®å¤")
    print("=" * 60)
    
    try:
        # ä½¿ç”¨ä¿®å¤åçš„DataProcessor
        from src.data.DataProcessor import DataProcessor
        
        processor = DataProcessor(
            base_dir="data/aeroclub-recsys-2025",
            chunk_size=100000,
        )
        print("âœ“ DataProcessor_Fixed å¯¼å…¥æˆåŠŸ")
        
        # æ£€æŸ¥å…³é”®æ–¹æ³•
        required_methods = [
            'process_pipeline',
            'segment_data',
            'concatenate_segments',
            'get_pipeline_status',
            '_verify_existing_segmentation'
        ]
        
        for method in required_methods:
            if hasattr(processor, method):
                print(f"âœ“ æ–¹æ³• {method} å­˜åœ¨")
            else:
                print(f"âœ— æ–¹æ³• {method} ç¼ºå¤±")
                return False
        
        # æµ‹è¯•çŠ¶æ€æ£€æŸ¥
        status = processor.get_pipeline_status()
        print(f"âœ“ çŠ¶æ€æ£€æŸ¥æˆåŠŸ: {list(status.keys())}")
        
        return True
        
    except Exception as e:
        print(f"âœ— DataProcessor æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_diagnostics():
    """æµ‹è¯•è¯Šæ–­å·¥å…·"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•è¯Šæ–­å·¥å…·")
    print("=" * 60)
    
    try:
        from data_diagnostics import DataDiagnostics
        
        diagnostics = DataDiagnostics()
        print("âœ“ DataDiagnostics å¯¼å…¥æˆåŠŸ")
        
        # æ£€æŸ¥å…³é”®æ–¹æ³•
        required_methods = [
            'analyze_segment_patterns',
            'compare_segmentation_results',
            'diagnose_missing_data',
            'generate_diagnostic_report'
        ]
        
        for method in required_methods:
            if hasattr(diagnostics, method):
                print(f"âœ“ æ–¹æ³• {method} å­˜åœ¨")
            else:
                print(f"âœ— æ–¹æ³• {method} ç¼ºå¤±")
                return False
        
        return True
        
    except Exception as e:
        print(f"âœ— è¯Šæ–­å·¥å…·æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_file_structure():
    """æ£€æŸ¥æ–‡ä»¶ç»“æ„"""
    print("\n" + "=" * 60)
    print("æ£€æŸ¥æ•°æ®æ–‡ä»¶ç»“æ„")
    print("=" * 60)
    
    base_dir = "data/aeroclub-recsys-2025"
    
    # æ£€æŸ¥åŸºç¡€æ–‡ä»¶
    required_files = [
        os.path.join(base_dir, "train.parquet"),
        os.path.join(base_dir, "test.parquet"),
    ]
    
    for file_path in required_files:
        if os.path.exists(file_path):
            size_mb = os.path.getsize(file_path) / 1024**2
            print(f"âœ“ {file_path} å­˜åœ¨ ({size_mb:.1f}MB)")
        else:
            print(f"âœ— {file_path} ä¸å­˜åœ¨")
    
    # æ£€æŸ¥ç›®å½•ç»“æ„
    required_dirs = [
        os.path.join(base_dir, "encoded"),
        os.path.join(base_dir, "segmented"),
        os.path.join(base_dir, "encoded", "train"),
        os.path.join(base_dir, "encoded", "test"),
        os.path.join(base_dir, "segmented", "train"),
        os.path.join(base_dir, "segmented", "test"),
    ]
    
    for dir_path in required_dirs:
        if os.path.exists(dir_path):
            print(f"âœ“ ç›®å½• {dir_path} å­˜åœ¨")
        else:
            print(f"! ç›®å½• {dir_path} ä¸å­˜åœ¨ï¼ˆå°†è¢«åˆ›å»ºï¼‰")

def run_quick_diagnosis():
    """è¿è¡Œå¿«é€Ÿè¯Šæ–­ï¼ˆå¦‚æœæ•°æ®å­˜åœ¨ï¼‰"""
    print("\n" + "=" * 60)
    print("è¿è¡Œå¿«é€Ÿè¯Šæ–­")
    print("=" * 60)
    
    try:
        from data_diagnostics import DataDiagnostics
        
        diagnostics = DataDiagnostics()
        base_dir = "data/aeroclub-recsys-2025"
        
        for data_type in ['train', 'test']:
            encoded_file = os.path.join(base_dir, "encoded", data_type, f"{data_type}_encoded.parquet")
            
            if os.path.exists(encoded_file):
                print(f"\næ£€æŸ¥ {data_type} æ•°æ®...")
                
                # å¿«é€Ÿæ¨¡å¼åˆ†æ
                pattern_analysis = diagnostics.analyze_segment_patterns(data_type)
                if pattern_analysis:
                    print(f"  æ€»è¡Œæ•°: {pattern_analysis['total_rows']:,}")
                    print(f"  æ€»ranker_id: {pattern_analysis['total_ranker_ids']:,}")
                    print("  çº§åˆ«åˆ†å¸ƒ:")
                    for level in [3, 2, 1, 0, -1]:
                        count = pattern_analysis['level_distribution'][level]
                        if count > 0:
                            level_name = f"Segment {level}" if level >= 0 else "æ— æœ‰æ•ˆSegment"
                            print(f"    {level_name}: {count:,} ranker_id")
                
                # å¦‚æœåˆ†å‰²æ–‡ä»¶å­˜åœ¨ï¼Œæ¯”è¾ƒç»“æœ
                segment_dir = os.path.join(base_dir, "segmented", data_type)
                if os.path.exists(segment_dir):
                    comparison = diagnostics.compare_segmentation_results(data_type)
                    if comparison:
                        integrity = comparison['integrity']
                        print(f"  åˆ†å‰²å®Œæ•´æ€§:")
                        print(f"    è¡Œæ•°åŒ¹é…: {'âœ“' if integrity['rows_match'] else 'âœ—'}")
                        print(f"    ranker_idåŒ¹é…: {'âœ“' if integrity['rankers_match'] else 'âœ—'}")
                        if not integrity['rows_match']:
                            orig = comparison['original']['total_rows']
                            seg = comparison['segmented']['total_rows']
                            print(f"    å·®å¼‚: {orig - seg} è¡Œ")
            else:
                print(f"  {data_type} ç¼–ç æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡è¯Šæ–­")
                
    except Exception as e:
        print(f"è¯Šæ–­å¤±è´¥: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("æ•°æ®åˆ†å‰²ä¿®å¤æµ‹è¯•")
    print("æ—¶é—´:", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    
    setup_test_logging()
    
    # åˆ‡æ¢åˆ°æ­£ç¡®çš„å·¥ä½œç›®å½•
    current_path = os.path.dirname(os.path.abspath(__file__))
    main_path = os.path.abspath(os.path.join(current_path, "..", ".."))
    if os.path.exists(main_path):
        os.chdir(main_path)
        print(f"å·¥ä½œç›®å½•: {main_path}")
    
    # è¿è¡Œæµ‹è¯•
    tests = [
        ("æ–‡ä»¶ç»“æ„æ£€æŸ¥", test_file_structure),
        ("DataSegmentä¿®å¤", test_data_segment_fix),
        ("DataProcessorä¿®å¤", test_data_processor_fix),
        ("è¯Šæ–­å·¥å…·", test_diagnostics),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âœ— {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    # è¿è¡Œè¯Šæ–­ï¼ˆå¦‚æœåŸºç¡€æµ‹è¯•é€šè¿‡ï¼‰
    if all(result for _, result in results):
        run_quick_diagnosis()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    for test_name, result in results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"{test_name}: {status}")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥è¿è¡Œä¿®å¤åçš„å¤„ç†æµæ°´çº¿ã€‚")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. è¿è¡Œ python DataProcessor_Fixed.py")
        print("2. æˆ–è€…åœ¨ä»£ç ä¸­å¯¼å…¥ä¿®å¤åçš„ç±»")
    else:
        print("\nâš ï¸  æœ‰æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¿®å¤çš„ä»£ç æ–‡ä»¶ã€‚")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)