"""
æ•°æ®å¤„ç†æ¨¡å— - ä¿®å¤æ’åé‡å¤é—®é¢˜ç‰ˆæœ¬

è¯¥æ¨¡å—è´Ÿè´£æ•°æ®çš„åŠ è½½ã€é¢„å¤„ç†ã€æŠ½æ ·å’Œç‰¹å¾å·¥ç¨‹
- å½»åº•ä¿®å¤äº†é¢„æµ‹ç»“æœåˆå¹¶æ—¶çš„æ’åé‡å¤é—®é¢˜
- å¼ºåŒ–äº†æ’åå”¯ä¸€æ€§ä¿è¯æœºåˆ¶
- æ”¹è¿›äº†é›†æˆé¢„æµ‹çš„ç¨³å®šæ€§
- å¢åŠ äº†å¤šå±‚æ¬¡çš„éªŒè¯å’Œä¿®å¤

ä½œè€…: Flight Ranking Team
ç‰ˆæœ¬: 2.2 (ä¿®å¤æ’åé‡å¤é—®é¢˜)
"""

import pandas as pd
import numpy as np
import pyarrow.parquet as pq
import gc
import os
from typing import Tuple, List, Optional, Dict, Any
from sklearn.model_selection import train_test_split
import warnings

# å¯¼å…¥è¿›åº¦æ¡å·¥å…·
try:
    from .progress_utils import create_data_loading_progress, progress_bar
except ImportError:
    from progress_utils import create_data_loading_progress, progress_bar

warnings.filterwarnings('ignore')


class DataProcessor:
    """æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, logger=None):
        """
        åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
        
        Args:
            logger: æ—¥å¿—è®°å½•å™¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨printè¾“å‡º
        """
        self.logger = logger
        self.feature_columns = None
        self.exclude_columns = ['Id', 'selected', 'ranker_id', 'profileId', 'companyID']
    
    def _log(self, message):
        """è®°å½•æ—¥å¿—"""
        if self.logger:
            self.logger.info(message)
        else:
            print(message)
    
    def load_data(self, file_path: str, use_sampling: bool = True, 
                  num_groups: int = 2000, min_group_size: int = 20) -> pd.DataFrame:
        """
        åŠ è½½æ•°æ®ï¼Œæ”¯æŒæŠ½æ ·å’Œå…¨é‡åŠ è½½ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
        
        Args:
            file_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            use_sampling: æ˜¯å¦ä½¿ç”¨æŠ½æ ·
            num_groups: æŠ½æ ·æ—¶çš„ç»„æ•°é‡
            min_group_size: æŠ½æ ·æ—¶æ¯ç»„æœ€å°æ•°æ®æ¡æ•°
            
        Returns:
            pd.DataFrame: åŠ è½½çš„æ•°æ®
        """
        self._log(f"ğŸ“‚ å¼€å§‹åŠ è½½æ•°æ®: {os.path.basename(file_path)}")
        
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½è¿›åº¦æ¡
        with create_data_loading_progress("è¯»å–æ–‡ä»¶") as pbar:
            # è¯»å–æ•°æ®
            pf = pq.ParquetFile(file_path)
            df = pf.read().to_pandas()
            pbar.update(1, "æ–‡ä»¶è¯»å–å®Œæˆ")
            
            self._log(f"ğŸ“Š åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
            
            if use_sampling:
                pbar.set_description("æ‰§è¡Œæ•°æ®æŠ½æ ·")
                self._log(f"ğŸ¯ ä½¿ç”¨æŠ½æ ·æ¨¡å¼: {num_groups}ä¸ªç»„, æ¯ç»„è‡³å°‘{min_group_size}æ¡æ•°æ®")
                df = self._sample_data(df, num_groups, min_group_size)
                pbar.update(1, "æŠ½æ ·å®Œæˆ")
            else:
                self._log("ğŸ“ˆ ä½¿ç”¨å…¨é‡æ•°æ®æ¨¡å¼")
                pbar.update(1, "è·³è¿‡æŠ½æ ·")
            
            # ä¼˜åŒ–å†…å­˜ä½¿ç”¨
            pbar.set_description("ä¼˜åŒ–å†…å­˜ä½¿ç”¨")
            df = self._optimize_memory_usage(df)
            pbar.update(1, "å†…å­˜ä¼˜åŒ–å®Œæˆ")
        
        self._log(f"âœ… æœ€ç»ˆæ•°æ®å½¢çŠ¶: {df.shape}")
        self._log(f"ğŸ“Š æ•°æ®åŒ…å«çš„ç»„æ•°: {df['ranker_id'].nunique()}")
        
        return df
    
    def _sample_data(self, df: pd.DataFrame, num_groups: int, min_group_size: int) -> pd.DataFrame:
        """
        åŸºäºranker_idçš„åˆ†ç»„æŠ½æ ·ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
        
        Args:
            df: åŸå§‹æ•°æ®
            num_groups: è¦æŠ½å–çš„ç»„æ•°é‡
            min_group_size: æ¯ç»„æœ€å°æ•°æ®æ¡æ•°
            
        Returns:
            pd.DataFrame: æŠ½æ ·åçš„æ•°æ®
        """
        # ç»Ÿè®¡æ¯ä¸ªranker_idçš„æ•°æ®é‡
        self._log("ğŸ“Š ç»Ÿè®¡ç»„ä¿¡æ¯...")
        group_counts = df['ranker_id'].value_counts()
        
        # ç­›é€‰æ»¡è¶³æœ€å°ç»„å¤§å°è¦æ±‚çš„ranker_id
        valid_groups = group_counts[group_counts >= min_group_size].index
        self._log(f"ğŸ“‹ æ»¡è¶³æœ€å°ç»„å¤§å°({min_group_size})çš„ç»„æ•°: {len(valid_groups)}")
        
        if len(valid_groups) < num_groups:
            self._log(f"âš ï¸  å¯ç”¨ç»„æ•°({len(valid_groups)})å°‘äºè¦æ±‚çš„ç»„æ•°({num_groups})")
            num_groups = len(valid_groups)
        
        # éšæœºæŠ½å–æŒ‡å®šæ•°é‡çš„ranker_id
        self._log("ğŸ² éšæœºé€‰æ‹©ç»„...")
        np.random.seed(42)
        selected_groups = np.random.choice(valid_groups, size=num_groups, replace=False)
        
        # åŸºäºé€‰ä¸­çš„ranker_idç­›é€‰æ•°æ®
        self._log("ğŸ”„ ç­›é€‰æ•°æ®...")
        sampled_df = df[df['ranker_id'].isin(selected_groups)].copy()
        
        self._log(f"ğŸ“Š æŠ½æ ·åæ•°æ®å½¢çŠ¶: {sampled_df.shape}")
        self._log(f"ğŸ“‹ å®é™…æŠ½å–çš„ç»„æ•°: {sampled_df['ranker_id'].nunique()}")
        
        return sampled_df
    
    def _optimize_memory_usage(self, df: pd.DataFrame) -> pd.DataFrame:
        """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
        # å°†æ•°å€¼åˆ—è½¬æ¢ä¸ºfloat32ä»¥èŠ‚çœå†…å­˜
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        df[numeric_cols] = df[numeric_cols].astype(np.float32)
        
        return df
    
    def prepare_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, List[str]]:
        """
        å‡†å¤‡ç‰¹å¾æ•°æ®
        
        Args:
            df: åŸå§‹æ•°æ®
            
        Returns:
            Tuple: (ç‰¹å¾çŸ©é˜µ, æ ‡ç­¾å‘é‡, ç‰¹å¾ååˆ—è¡¨)
        """
        self._log("å‡†å¤‡ç‰¹å¾æ•°æ®...")
        
        # é€‰æ‹©æ•°å€¼å‹ç‰¹å¾
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        # æ’é™¤ä¸éœ€è¦çš„ç‰¹å¾
        feature_cols = [col for col in numeric_cols if col not in self.exclude_columns]
        self.feature_columns = feature_cols
        
        # å¤„ç†ç¼ºå¤±å€¼
        df[feature_cols] = df[feature_cols].fillna(df[feature_cols].median())
        
        # å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
        X = df[feature_cols].values.astype(np.float32)
        y = df['selected'].values.astype(np.float32)
        
        self._log(f"ç‰¹å¾ç»´åº¦: {X.shape}")
        self._log(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
        
        return X, y, feature_cols
    
    def prepare_ranking_data(self, df: pd.DataFrame, test_size: float = 0.2, 
                           random_state: int = 42) -> Tuple[np.ndarray, ...]:
        """
        å‡†å¤‡æ’åºæ¨¡å‹æ•°æ®ï¼ŒåŒ…æ‹¬è®­ç»ƒæµ‹è¯•é›†åˆ’åˆ†
        
        Args:
            df: åŸå§‹æ•°æ®
            test_size: æµ‹è¯•é›†æ¯”ä¾‹
            random_state: éšæœºç§å­
            
        Returns:
            Tuple: åŒ…å«è®­ç»ƒæµ‹è¯•æ•°æ®çš„å…ƒç»„
        """
        self._log("å‡†å¤‡æ’åºæ¨¡å‹æ•°æ®...")
        
        # å‡†å¤‡ç‰¹å¾
        X, y, feature_cols = self.prepare_features(df)
        groups = df['ranker_id'].values
        
        # æŒ‰ranker_idåˆ†ç»„åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        unique_groups = df['ranker_id'].unique()
        train_groups, test_groups = train_test_split(
            unique_groups, test_size=test_size, random_state=random_state
        )
        
        train_mask = df['ranker_id'].isin(train_groups)
        test_mask = df['ranker_id'].isin(test_groups)
        
        X_train = X[train_mask]
        X_test = X[test_mask]
        y_train = y[train_mask]
        y_test = y[test_mask]
        
        # è®¡ç®—ç»„å¤§å°
        train_group_sizes = self._calculate_group_sizes(groups[train_mask])
        test_group_sizes = self._calculate_group_sizes(groups[test_mask])
        
        # æµ‹è¯•é›†ä¿¡æ¯
        test_info = df[test_mask][['ranker_id', 'selected']].copy()
        
        self._log(f"è®­ç»ƒé›†å½¢çŠ¶: {X_train.shape}")
        self._log(f"æµ‹è¯•é›†å½¢çŠ¶: {X_test.shape}")
        self._log(f"è®­ç»ƒç»„æ•°: {len(train_group_sizes)}")
        self._log(f"æµ‹è¯•ç»„æ•°: {len(test_group_sizes)}")
        
        return (X_train, X_test, y_train, y_test, 
                train_group_sizes, test_group_sizes, 
                feature_cols, test_info)
    
    def _calculate_group_sizes(self, groups: np.ndarray) -> List[int]:
        """è®¡ç®—æ¯ä¸ªç»„çš„å¤§å°"""
        group_sizes = []
        current_group = groups[0]
        current_size = 1
        
        for i in range(1, len(groups)):
            if groups[i] == current_group:
                current_size += 1
            else:
                group_sizes.append(current_size)
                current_group = groups[i]
                current_size = 1
        group_sizes.append(current_size)  # æ·»åŠ æœ€åä¸€ä¸ªç»„
        
        return group_sizes
    
    def load_test_data(self, file_path: str) -> pd.DataFrame:
        """
        åŠ è½½æµ‹è¯•æ•°æ®ï¼ˆä¸æŠ½æ ·ï¼ŒåŠ è½½å…¨éƒ¨æ•°æ®ï¼‰
        
        Args:
            file_path: æµ‹è¯•æ–‡ä»¶è·¯å¾„
            
        Returns:
            pd.DataFrame: æµ‹è¯•æ•°æ®
        """
        self._log(f"åŠ è½½æµ‹è¯•æ•°æ®: {file_path}")
        
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        # è¯»å–æµ‹è¯•æ•°æ®
        pf = pq.ParquetFile(file_path)
        test_df = pf.read().to_pandas()
        
        # ä¼˜åŒ–å†…å­˜ä½¿ç”¨
        test_df = self._optimize_memory_usage(test_df)
        
        self._log(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_df.shape}")
        
        return test_df
    
    def prepare_test_features(self, test_df: pd.DataFrame) -> Tuple[np.ndarray, List[int]]:
        """
        å‡†å¤‡æµ‹è¯•æ•°æ®ç‰¹å¾
        
        Args:
            test_df: æµ‹è¯•æ•°æ®
            
        Returns:
            Tuple: (ç‰¹å¾çŸ©é˜µ, ç»„å¤§å°åˆ—è¡¨)
        """
        if self.feature_columns is None:
            raise ValueError("ç‰¹å¾åˆ—å°šæœªç¡®å®šï¼Œè¯·å…ˆè°ƒç”¨prepare_featuresæ–¹æ³•")
        
        # ç¡®ä¿æµ‹è¯•æ•°æ®åŒ…å«æ‰€éœ€ç‰¹å¾
        missing_features = set(self.feature_columns) - set(test_df.columns)
        if missing_features:
            self._log(f"è­¦å‘Š: æµ‹è¯•æ•°æ®ç¼ºå°‘ç‰¹å¾: {missing_features}")
            # ä¸ºç¼ºå¤±ç‰¹å¾æ·»åŠ 0å€¼
            for feature in missing_features:
                test_df[feature] = 0.0
        
        # å¤„ç†ç¼ºå¤±å€¼
        test_df[self.feature_columns] = test_df[self.feature_columns].fillna(
            test_df[self.feature_columns].median()
        )
        
        X_test = test_df[self.feature_columns].values.astype(np.float32)
        
        # è®¡ç®—ç»„å¤§å°
        groups = test_df['ranker_id'].values
        group_sizes = self._calculate_group_sizes(groups)
        
        return X_test, group_sizes
    
    def save_predictions(self, test_df: pd.DataFrame, predictions: Dict[str, Dict[str, np.ndarray]], 
                        output_path: str) -> str:
        """
        ä¿å­˜é¢„æµ‹ç»“æœ
        
        Args:
            test_df: æµ‹è¯•æ•°æ®
            predictions: é¢„æµ‹ç»“æœå­—å…¸
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # åˆ›å»ºç»“æœDataFrame
        result_df = test_df[['Id', 'ranker_id']].copy()
        
        # æ·»åŠ é¢„æµ‹ç»“æœ
        for model_type, pred in predictions.items():
            if 'scores' in pred:
                result_df[f'{model_type}_score'] = pred['scores']
            if 'ranks' in pred:
                result_df[f'{model_type}_rank'] = pred['ranks']
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        result_df.to_parquet(output_path, index=False)
        self._log(f"é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
        return output_path


class PredictionMerger:
    """é¢„æµ‹ç»“æœåˆå¹¶å™¨ - ä¿®å¤æ’åé‡å¤é—®é¢˜ç‰ˆæœ¬"""
    
    def __init__(self, logger=None):
        """
        åˆå§‹åŒ–é¢„æµ‹ç»“æœåˆå¹¶å™¨
        
        Args:
            logger: æ—¥å¿—è®°å½•å™¨
        """
        self.logger = logger
    
    def _log(self, message):
        """è®°å½•æ—¥å¿—"""
        if self.logger:
            self.logger.info(message)
        else:
            print(message)
    
    def _validate_data_quality(self, df: pd.DataFrame, stage: str = "unknown"):
        """
        éªŒè¯æ•°æ®è´¨é‡ï¼Œæ£€æŸ¥å¼‚å¸¸å€¼
        
        Args:
            df: è¦éªŒè¯çš„DataFrame
            stage: éªŒè¯é˜¶æ®µåç§°
        """
        self._log(f"ğŸ” éªŒè¯æ•°æ®è´¨é‡ - {stage}")
        
        # æ£€æŸ¥æ•°å€¼åˆ—çš„å¼‚å¸¸å€¼
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            nan_count = df[col].isna().sum()
            inf_count = np.isinf(df[col]).sum()
            
            if nan_count > 0:
                self._log(f"  âš ï¸ {col}: {nan_count} ä¸ª NaN å€¼")
            if inf_count > 0:
                self._log(f"  âš ï¸ {col}: {inf_count} ä¸ª æ— ç©·å¤§å€¼")
    
    def _clean_prediction_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ¸…ç†é¢„æµ‹æ•°æ®ä¸­çš„å¼‚å¸¸å€¼
        
        Args:
            df: åŒ…å«é¢„æµ‹ç»“æœçš„DataFrame
            
        Returns:
            pd.DataFrame: æ¸…ç†åçš„DataFrame
        """
        self._log("ğŸ§¹ æ¸…ç†é¢„æµ‹æ•°æ®...")
        
        # æ‰¾åˆ°æ‰€æœ‰åˆ†æ•°å’Œæ’ååˆ—
        score_columns = [col for col in df.columns if col.endswith('_score')]
        rank_columns = [col for col in df.columns if col.endswith('_rank')]
        
        # æ¸…ç†åˆ†æ•°åˆ—
        for col in score_columns:
            if col in df.columns:
                # æ›¿æ¢æ— ç©·å¤§å€¼ä¸ºNaN
                df[col] = df[col].replace([np.inf, -np.inf], np.nan)
                
                # ç»Ÿè®¡å¹¶å¤„ç†NaNå€¼
                nan_count = df[col].isna().sum()
                if nan_count > 0:
                    self._log(f"  å¤„ç† {col}: {nan_count} ä¸ªå¼‚å¸¸å€¼")
                    # ç”¨è¯¥åˆ—çš„ä¸­ä½æ•°å¡«å……NaNå€¼
                    median_val = df[col].median()
                    if pd.isna(median_val):  # å¦‚æœä¸­ä½æ•°ä¹Ÿæ˜¯NaNï¼Œä½¿ç”¨0
                        median_val = 0.0
                    df[col] = df[col].fillna(median_val)
        
        # æ¸…ç†æ’ååˆ—
        for col in rank_columns:
            if col in df.columns:
                # æ›¿æ¢æ— ç©·å¤§å€¼ä¸ºNaN
                df[col] = df[col].replace([np.inf, -np.inf], np.nan)
                
                # ç»Ÿè®¡å¹¶å¤„ç†NaNå€¼
                nan_count = df[col].isna().sum()
                if nan_count > 0:
                    self._log(f"  å¤„ç† {col}: {nan_count} ä¸ªå¼‚å¸¸å€¼")
                    # å¯¹äºæ’åï¼Œç”¨è¯¥ç»„å†…çš„æœ€å¤§æ’å+1å¡«å……
                    df[col] = df.groupby('ranker_id')[col].transform(
                        lambda x: x.fillna(x.max() + 1 if not x.isna().all() else len(x))
                    )
        
        return df
    
    def merge_predictions(self, prediction_files: List[str], 
                         submission_file: str, 
                         output_file: str,
                         ensemble_method: str = 'average') -> str:
        """
        åˆå¹¶å¤šä¸ªé¢„æµ‹æ–‡ä»¶å¹¶ä¸submissionæ–‡ä»¶å¯¹åº”ï¼ˆä¿®å¤æ’åé‡å¤é—®é¢˜ç‰ˆæœ¬ï¼‰
        
        Args:
            prediction_files: é¢„æµ‹æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            submission_file: submissionæ¨¡æ¿æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            ensemble_method: é›†æˆæ–¹æ³• ('average', 'voting', 'weighted')
            
        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        self._log("å¼€å§‹åˆå¹¶é¢„æµ‹ç»“æœ...")
        
        # è¯»å–submissionæ–‡ä»¶ï¼Œå¤„ç†ç¼–ç é—®é¢˜
        if not os.path.exists(submission_file):
            raise FileNotFoundError(f"Submissionæ–‡ä»¶ä¸å­˜åœ¨: {submission_file}")
        
        # å°è¯•ä¸åŒçš„ç¼–ç æ–¹å¼è¯»å–submissionæ–‡ä»¶
        submission_df = None
        encodings_to_try = ['utf-8', 'gbk', 'gb2312', 'latin-1', 'cp1252']
        
        for encoding in encodings_to_try:
            try:
                if submission_file.endswith('.csv'):
                    submission_df = pd.read_csv(submission_file, encoding=encoding)
                elif submission_file.endswith('.parquet'):
                    submission_df = pd.read_parquet(submission_file)
                else:
                    # å°è¯•ä½œä¸ºCSVè¯»å–
                    submission_df = pd.read_csv(submission_file, encoding=encoding)
                
                self._log(f"æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç è¯»å–submissionæ–‡ä»¶")
                break
                
            except UnicodeDecodeError:
                continue
            except Exception as e:
                self._log(f"ä½¿ç”¨ {encoding} ç¼–ç è¯»å–å¤±è´¥: {str(e)}")
                continue
        
        if submission_df is None:
            raise ValueError(f"æ— æ³•è¯»å–submissionæ–‡ä»¶ï¼Œå°è¯•äº†ä»¥ä¸‹ç¼–ç : {encodings_to_try}")
        
        self._log(f"Submissionæ–‡ä»¶å½¢çŠ¶: {submission_df.shape}")
        self._validate_data_quality(submission_df, "submission")
        
        # è¯»å–æ‰€æœ‰é¢„æµ‹æ–‡ä»¶
        prediction_dfs = []
        for file_path in prediction_files:
            if os.path.exists(file_path):
                try:
                    pred_df = pd.read_parquet(file_path)
                    # éªŒè¯å’Œæ¸…ç†é¢„æµ‹æ•°æ®
                    self._validate_data_quality(pred_df, f"prediction - {os.path.basename(file_path)}")
                    pred_df = self._clean_prediction_data(pred_df)
                    prediction_dfs.append(pred_df)
                    self._log(f"è¯»å–é¢„æµ‹æ–‡ä»¶: {file_path}, å½¢çŠ¶: {pred_df.shape}")
                except Exception as e:
                    self._log(f"è¯»å–é¢„æµ‹æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {str(e)}")
            else:
                self._log(f"è­¦å‘Š: é¢„æµ‹æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        if not prediction_dfs:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„é¢„æµ‹æ–‡ä»¶")
        
        # åˆå¹¶æ‰€æœ‰é¢„æµ‹ç»“æœ
        merged_predictions = pd.concat(prediction_dfs, ignore_index=True)
        self._validate_data_quality(merged_predictions, "merged predictions")
        
        # æ£€æŸ¥submissionå’Œpredictionçš„åˆ—æ˜¯å¦åŒ¹é…
        common_columns = set(submission_df.columns) & set(merged_predictions.columns)
        self._log(f"å…±åŒåˆ—: {list(common_columns)}")
        
        if 'Id' not in common_columns and 'ranker_id' not in common_columns:
            self._log("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°å…±åŒçš„åŒ¹é…åˆ—(Id, ranker_id)")
            # å°è¯•å…¶ä»–å¯èƒ½çš„åˆ—å
            possible_id_cols = ['id', 'ID', 'Id', 'flight_id']
            possible_ranker_cols = ['ranker_id', 'rankerId', 'ranker_ID']
            
            for col in possible_id_cols:
                if col in submission_df.columns and col in merged_predictions.columns:
                    submission_df = submission_df.rename(columns={col: 'Id'})
                    merged_predictions = merged_predictions.rename(columns={col: 'Id'})
                    break
            
            for col in possible_ranker_cols:
                if col in submission_df.columns and col in merged_predictions.columns:
                    submission_df = submission_df.rename(columns={col: 'ranker_id'})
                    merged_predictions = merged_predictions.rename(columns={col: 'ranker_id'})
                    break
        
        # ä¸submissionæ–‡ä»¶å¯¹åº”
        try:
            if 'Id' in submission_df.columns and 'ranker_id' in submission_df.columns:
                final_df = submission_df.merge(
                    merged_predictions, 
                    on=['Id', 'ranker_id'], 
                    how='left'
                )
            elif 'Id' in submission_df.columns:
                final_df = submission_df.merge(
                    merged_predictions, 
                    on=['Id'], 
                    how='left'
                )
            else:
                # å¦‚æœæ²¡æœ‰åˆé€‚çš„åŒ¹é…åˆ—ï¼Œç›´æ¥ä½¿ç”¨é¢„æµ‹ç»“æœ
                self._log("è­¦å‘Š: æ— æ³•ä¸submissionæ–‡ä»¶åŒ¹é…ï¼Œç›´æ¥ä½¿ç”¨é¢„æµ‹ç»“æœ")
                final_df = merged_predictions
        
        except Exception as e:
            self._log(f"åˆå¹¶æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            self._log("ä½¿ç”¨é¢„æµ‹æ•°æ®ä½œä¸ºæœ€ç»ˆç»“æœ")
            final_df = merged_predictions
        
        # éªŒè¯åˆå¹¶åçš„æ•°æ®
        self._validate_data_quality(final_df, "after merge")
        
        # å¤„ç†é›†æˆé¢„æµ‹ï¼ˆå…³é”®ä¿®å¤ï¼‰
        final_df = self._ensemble_predictions_robust(final_df, ensemble_method)
        
        # æœ€ç»ˆéªŒè¯å’Œä¿®å¤
        self._validate_data_quality(final_df, "after ensemble")
        final_df = self._comprehensive_ranking_fix(final_df)
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        try:
            final_df.to_parquet(output_file, index=False)
            self._log(f"æœ€ç»ˆé¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        except Exception as e:
            # å¦‚æœparquetä¿å­˜å¤±è´¥ï¼Œå°è¯•ä¿å­˜ä¸ºCSV
            csv_output = output_file.replace('.parquet', '.csv')
            final_df.to_csv(csv_output, index=False, encoding='utf-8')
            self._log(f"æœ€ç»ˆé¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {csv_output}")
            output_file = csv_output
        
        return output_file
    
    def _ensemble_predictions_robust(self, df: pd.DataFrame, method: str) -> pd.DataFrame:
        """
        ç¨³å¥çš„é›†æˆå¤šä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ - å½»åº•ä¿®å¤æ’åé‡å¤é—®é¢˜
        
        Args:
            df: åŒ…å«å¤šä¸ªæ¨¡å‹é¢„æµ‹çš„DataFrame
            method: é›†æˆæ–¹æ³•
            
        Returns:
            pd.DataFrame: é›†æˆåçš„ç»“æœï¼Œç¡®ä¿æ’åå”¯ä¸€ä¸”è¿ç»­
        """
        self._log(f"ğŸ¯ æ‰§è¡Œç¨³å¥é›†æˆé¢„æµ‹ï¼Œæ–¹æ³•: {method}")
        
        # æ‰¾åˆ°æ‰€æœ‰åˆ†æ•°åˆ—å’Œæ’ååˆ—
        score_columns = [col for col in df.columns if col.endswith('_score')]
        rank_columns = [col for col in df.columns if col.endswith('_rank')]
        
        self._log(f"æ‰¾åˆ°åˆ†æ•°åˆ—: {score_columns}")
        self._log(f"æ‰¾åˆ°æ’ååˆ—: {rank_columns}")
        
        if not score_columns and not rank_columns:
            self._log("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°é¢„æµ‹åˆ†æ•°æˆ–æ’ååˆ—")
            return self._create_emergency_rankings(df)
        
        try:
            if method == 'average' and score_columns:
                # å¹³å‡åˆ†æ•°æ–¹æ³•
                df = self._average_score_ensemble_robust(df, score_columns)
                
            elif method == 'voting' and rank_columns:
                # æ’åæŠ•ç¥¨æ–¹æ³•  
                df = self._voting_rank_ensemble_robust(df, rank_columns)
                
            elif method == 'weighted' and score_columns:
                # åŠ æƒå¹³å‡æ–¹æ³•
                df = self._weighted_average_ensemble_robust(df, score_columns)
                
            else:
                # å›é€€åˆ°é»˜è®¤æ–¹æ³•
                self._log("ä½¿ç”¨é»˜è®¤é›†æˆæ–¹æ³•")
                df = self._create_emergency_rankings(df)
            
            # å…³é”®æ­¥éª¤ï¼šç¡®ä¿æœ€ç»ˆæ’åçš„å”¯ä¸€æ€§
            if 'final_rank' in df.columns and 'ranker_id' in df.columns:
                df = self._guarantee_ranking_uniqueness(df)
            
            self._log("âœ… ç¨³å¥é›†æˆé¢„æµ‹å®Œæˆ")
            
        except Exception as e:
            self._log(f"âŒ é›†æˆé¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            # å¦‚æœé›†æˆå¤±è´¥ï¼Œåˆ›å»ºå®‰å…¨çš„å¤‡ç”¨æ’å
            df = self._create_emergency_rankings(df)
        
        return df

    def _average_score_ensemble_robust(self, df: pd.DataFrame, score_columns: list) -> pd.DataFrame:
        """
        ç¨³å¥ç‰ˆæœ¬çš„å¹³å‡åˆ†æ•°é›†æˆ
        
        Args:
            df: åŒ…å«åˆ†æ•°åˆ—çš„DataFrame
            score_columns: åˆ†æ•°åˆ—ååˆ—è¡¨
            
        Returns:
            pd.DataFrame: é›†æˆåçš„DataFrame
        """
        self._log("æ‰§è¡Œç¨³å¥å¹³å‡åˆ†æ•°é›†æˆ...")
        
        # æ¸…ç†å’ŒéªŒè¯åˆ†æ•°åˆ—
        for col in score_columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            df[col] = df[col].replace([np.inf, -np.inf], np.nan)
        
        # è®¡ç®—å¹³å‡åˆ†æ•°ï¼Œè·³è¿‡NaNå€¼
        df['ensemble_score'] = df[score_columns].mean(axis=1, skipna=True)
        
        # å¤„ç†ä»ç„¶æ˜¯NaNçš„æƒ…å†µ
        df['ensemble_score'] = df['ensemble_score'].fillna(0.0)
        
        # å…³é”®ä¿®å¤ï¼šåŸºäºé›†æˆåˆ†æ•°è®¡ç®—ç¨³å¥çš„å”¯ä¸€æ’å
        if 'ranker_id' in df.columns:
            df['final_rank'] = self._calculate_robust_group_ranks(
                df['ensemble_score'].values, 
                df['ranker_id'].values,
                score_based=True
            )
        else:
            df['final_rank'] = 1
        
        return df

    def _voting_rank_ensemble_robust(self, df: pd.DataFrame, rank_columns: list) -> pd.DataFrame:
        """
        ç¨³å¥ç‰ˆæœ¬çš„æ’åæŠ•ç¥¨é›†æˆ
        
        Args:
            df: åŒ…å«æ’ååˆ—çš„DataFrame
            rank_columns: æ’ååˆ—ååˆ—è¡¨
            
        Returns:
            pd.DataFrame: é›†æˆåçš„DataFrame
        """
        self._log("æ‰§è¡Œç¨³å¥æ’åæŠ•ç¥¨é›†æˆ...")
        
        # æ¸…ç†å’ŒéªŒè¯æ’ååˆ—
        for col in rank_columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            df[col] = df[col].replace([np.inf, -np.inf], np.nan)
        
        # è®¡ç®—å¹³å‡æ’å
        df['ensemble_rank'] = df[rank_columns].mean(axis=1, skipna=True)
        
        # å¤„ç†NaNå€¼ - ç”¨ç»„å†…æœ€å¤§æ’å+1å¡«å……
        if 'ranker_id' in df.columns:
            df['ensemble_rank'] = df.groupby('ranker_id')['ensemble_rank'].transform(
                lambda x: x.fillna(x.max() + 1 if not x.isna().all() else len(x))
            )
        else:
            df['ensemble_rank'] = df['ensemble_rank'].fillna(1.0)
        
        # å…³é”®ä¿®å¤ï¼šåŸºäºå¹³å‡æ’åé‡æ–°åˆ†é…ç¨³å¥çš„å”¯ä¸€æ’å
        if 'ranker_id' in df.columns:
            # å°†å¹³å‡æ’åè½¬æ¢ä¸ºä¼ªåˆ†æ•°ï¼ˆæ’åè¶Šå°ï¼Œåˆ†æ•°è¶Šé«˜ï¼‰
            pseudo_scores = -df['ensemble_rank'].values
            df['final_rank'] = self._calculate_robust_group_ranks(
                pseudo_scores,
                df['ranker_id'].values,
                score_based=True
            )
        else:
            df['final_rank'] = df['ensemble_rank'].round().clip(lower=1).astype(int)
        
        return df

    def _weighted_average_ensemble_robust(self, df: pd.DataFrame, score_columns: list) -> pd.DataFrame:
        """
        ç¨³å¥ç‰ˆæœ¬çš„åŠ æƒå¹³å‡é›†æˆ
        
        Args:
            df: åŒ…å«åˆ†æ•°åˆ—çš„DataFrame  
            score_columns: åˆ†æ•°åˆ—ååˆ—è¡¨
            
        Returns:
            pd.DataFrame: é›†æˆåçš„DataFrame
        """
        self._log("æ‰§è¡Œç¨³å¥åŠ æƒå¹³å‡é›†æˆ...")
        
        # æ¸…ç†åˆ†æ•°åˆ—
        for col in score_columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            df[col] = df[col].replace([np.inf, -np.inf], np.nan)
        
        # ç®€å•ç­‰æƒé‡ï¼ˆå¯ä»¥æ ¹æ®æ¨¡å‹æ€§èƒ½è°ƒæ•´æƒé‡ï¼‰
        weights = np.ones(len(score_columns)) / len(score_columns)
        
        # è®¡ç®—åŠ æƒå¹³å‡ï¼Œæ­£ç¡®å¤„ç†NaNå€¼
        score_matrix = df[score_columns].values
        valid_mask = ~np.isnan(score_matrix)
        
        weighted_scores = []
        for i in range(len(df)):
            row_scores = score_matrix[i]
            row_mask = valid_mask[i]
            
            if row_mask.any():  # å¦‚æœæœ‰æœ‰æ•ˆå€¼
                valid_scores = row_scores[row_mask]
                valid_weights = weights[row_mask]
                valid_weights = valid_weights / valid_weights.sum()  # é‡æ–°å½’ä¸€åŒ–æƒé‡
                weighted_score = np.average(valid_scores, weights=valid_weights)
            else:
                weighted_score = 0.0
            
            weighted_scores.append(weighted_score)
        
        df['ensemble_score'] = weighted_scores
        
        # åŸºäºåŠ æƒåˆ†æ•°è®¡ç®—ç¨³å¥çš„å”¯ä¸€æ’å
        if 'ranker_id' in df.columns:
            df['final_rank'] = self._calculate_robust_group_ranks(
                df['ensemble_score'].values,
                df['ranker_id'].values,
                score_based=True
            )
        else:
            df['final_rank'] = 1
        
        return df

    def _calculate_robust_group_ranks(self, values: np.ndarray, ranker_ids: np.ndarray, 
                                     score_based: bool = True) -> np.ndarray:
        """
        è®¡ç®—ç¨³å¥çš„ç»„å†…æ’åï¼Œç¡®ä¿æ¯ç»„æ’åå”¯ä¸€ä¸”è¿ç»­
        
        Args:
            values: åˆ†æ•°æˆ–æ’åå€¼
            ranker_ids: ranker_idæ•°ç»„
            score_based: æ˜¯å¦åŸºäºåˆ†æ•°ï¼ˆTrueï¼‰è¿˜æ˜¯æ’åï¼ˆFalseï¼‰
            
        Returns:
            np.ndarray: å”¯ä¸€ä¸”è¿ç»­çš„æ’å
        """
        ranks = np.zeros_like(values, dtype=int)
        
        # æŒ‰ranker_idåˆ†ç»„å¤„ç†
        unique_rankers = np.unique(ranker_ids)
        
        for ranker_id in unique_rankers:
            group_mask = ranker_ids == ranker_id
            group_values = values[group_mask]
            group_size = len(group_values)
            
            if group_size == 1:
                # å•ä¸ªå…ƒç´ çš„ç»„ï¼Œæ’åç›´æ¥ä¸º1
                ranks[group_mask] = 1
            else:
                # å¤šä¸ªå…ƒç´ çš„ç»„ï¼Œç¡®ä¿æ’åå”¯ä¸€
                # ä½¿ç”¨ranker_idçš„å“ˆå¸Œå€¼ä½œä¸ºéšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
                unique_seed = abs(hash(str(ranker_id))) % 1000000
                np.random.seed(unique_seed)
                
                # æ·»åŠ å”¯ä¸€çš„å™ªå£°
                noise_scale = 1e-8
                noise = np.random.random(len(group_values)) * noise_scale
                
                # ä¸ºæ¯ä¸ªä½ç½®æ·»åŠ ä¸åŒçš„åç§»
                position_offset = np.arange(len(group_values)) * 1e-10
                noisy_values = group_values + noise + position_offset
                
                if score_based:
                    # åŸºäºåˆ†æ•°ï¼šåˆ†æ•°è¶Šé«˜æ’åè¶Šé å‰
                    sorted_indices = np.argsort(-noisy_values)
                else:
                    # åŸºäºæ’åï¼šæ’åè¶Šå°è¶Šé å‰
                    sorted_indices = np.argsort(noisy_values)
                
                # åˆ†é…å”¯ä¸€ä¸”è¿ç»­çš„æ’å
                group_ranks = np.zeros(group_size, dtype=int)
                for rank, idx in enumerate(sorted_indices):
                    group_ranks[idx] = rank + 1
                
                ranks[group_mask] = group_ranks
                
                # éªŒè¯å½“å‰ç»„çš„æ’å
                unique_ranks = set(group_ranks)
                expected_ranks = set(range(1, group_size + 1))
                if unique_ranks != expected_ranks:
                    # å¦‚æœä»æœ‰é—®é¢˜ï¼Œå¼ºåˆ¶ä¿®å¤
                    self._log(f"è­¦å‘Šï¼šranker_id {ranker_id} æ’åè®¡ç®—å¤±è´¥ï¼Œå¼ºåˆ¶ä¿®å¤")
                    ranks[group_mask] = np.random.permutation(range(1, group_size + 1))
        
        return ranks

    def _guarantee_ranking_uniqueness(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        â­ ç»ˆæä¿®å¤æ–¹æ³•ï¼šç»å¯¹ä¿è¯æ’åçš„å”¯ä¸€æ€§å’Œè¿ç»­æ€§
        
        Args:
            df: åŒ…å«æ’åçš„DataFrame
            
        Returns:
            pd.DataFrame: ç»å¯¹ä¿®å¤åçš„DataFrame
        """
        self._log("ğŸ”§ æ‰§è¡Œç»ˆææ’åå”¯ä¸€æ€§ä¿è¯...")
        
        problem_groups = 0
        total_groups = df['ranker_id'].nunique()
        
        for ranker_id in df['ranker_id'].unique():
            group_mask = df['ranker_id'] == ranker_id
            group_data = df[group_mask]
            group_size = len(group_data)
            
            # æ£€æŸ¥å½“å‰æ’åæ˜¯å¦ç¬¦åˆè¦æ±‚
            current_ranks = sorted(group_data['final_rank'].values)
            expected_ranks = list(range(1, group_size + 1))
            
            if current_ranks != expected_ranks:
                problem_groups += 1
                
                # ç»ˆæä¿®å¤ç­–ç•¥ï¼šä½¿ç”¨å¤šç§å¤‡ç”¨æ–¹æ¡ˆ
                fixed_ranks = None
                
                # ç­–ç•¥1ï¼šåŸºäºé›†æˆåˆ†æ•°é‡æ–°æ’å
                if 'ensemble_score' in group_data.columns:
                    scores = group_data['ensemble_score'].values
                    # ä½¿ç”¨ranker_idä½œä¸ºéšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§å’Œå”¯ä¸€æ€§
                    unique_seed = abs(hash(str(ranker_id))) % 1000000
                    np.random.seed(unique_seed)
                    noise = np.random.random(len(scores)) * 1e-6
                    noisy_scores = scores + noise
                    sorted_indices = np.argsort(-noisy_scores)
                    fixed_ranks = np.zeros(group_size, dtype=int)
                    for rank, idx in enumerate(sorted_indices):
                        fixed_ranks[idx] = rank + 1
                
                # ç­–ç•¥2ï¼šåŸºäºé›†æˆæ’åé‡æ–°æ’å
                elif 'ensemble_rank' in group_data.columns:
                    ranks_vals = group_data['ensemble_rank'].values
                    unique_seed = abs(hash(str(ranker_id) + "_rank")) % 1000000
                    np.random.seed(unique_seed)
                    noise = np.random.random(len(ranks_vals)) * 1e-6
                    noisy_ranks = ranks_vals + noise
                    sorted_indices = np.argsort(noisy_ranks)
                    fixed_ranks = np.zeros(group_size, dtype=int)
                    for rank, idx in enumerate(sorted_indices):
                        fixed_ranks[idx] = rank + 1
                
                # ç­–ç•¥3ï¼šå®Œå…¨éšæœºæ’åˆ—ï¼ˆæœ€åæ‰‹æ®µï¼‰
                if fixed_ranks is None:
                    unique_seed = abs(hash(str(ranker_id) + "_final")) % 1000000
                    np.random.seed(unique_seed)
                    fixed_ranks = np.random.permutation(range(1, group_size + 1))
                
                # åº”ç”¨ä¿®å¤åçš„æ’å
                df.loc[group_mask, 'final_rank'] = fixed_ranks
                
                # å†æ¬¡éªŒè¯
                new_ranks = sorted(fixed_ranks)
                if new_ranks != expected_ranks:
                    # å¦‚æœè¿˜æ˜¯æœ‰é—®é¢˜ï¼Œä½¿ç”¨æœ€ç®€å•çš„é¡ºåºæ’å
                    df.loc[group_mask, 'final_rank'] = list(range(1, group_size + 1))
        
        if problem_groups > 0:
            self._log(f"ğŸ”§ ç»ˆæä¿®å¤å®Œæˆï¼šä¿®å¤äº† {problem_groups}/{total_groups} ä¸ªæ’åé—®é¢˜ç»„")
        else:
            self._log(f"âœ… æ‰€æœ‰ {total_groups} ä¸ªç»„çš„æ’åéƒ½å·²å®Œç¾")
        
        return df

    def _create_emergency_rankings(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        åˆ›å»ºç´§æ€¥å¤‡ç”¨æ’åï¼ˆå½“æ‰€æœ‰å…¶ä»–æ–¹æ³•éƒ½å¤±è´¥æ—¶ï¼‰
        
        Args:
            df: DataFrame
            
        Returns:
            pd.DataFrame: æ·»åŠ äº†ç´§æ€¥æ’åçš„DataFrame
        """
        self._log("åˆ›å»ºç´§æ€¥å¤‡ç”¨æ’å...")
        
        if 'ranker_id' in df.columns:
            # ä¸ºæ¯ä¸ªç»„åˆ›å»ºç¡®å®šæ€§çš„éšæœºæ’å
            for ranker_id in df['ranker_id'].unique():
                group_mask = df['ranker_id'] == ranker_id
                group_size = group_mask.sum()
                
                # ä½¿ç”¨ranker_idä½œä¸ºç§å­ç¡®ä¿å¯é‡å¤æ€§
                emergency_seed = abs(hash(str(ranker_id) + "_emergency")) % 1000000
                np.random.seed(emergency_seed)
                ranks = np.random.permutation(range(1, group_size + 1))
                df.loc[group_mask, 'final_rank'] = ranks
        else:
            df['final_rank'] = 1
        
        return df

    def _comprehensive_ranking_fix(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å…¨é¢çš„æ’åä¿®å¤ï¼ˆæœ€ç»ˆæ£€æŸ¥å’Œä¿®å¤ï¼‰
        
        Args:
            df: DataFrame
            
        Returns:
            pd.DataFrame: å…¨é¢ä¿®å¤åçš„DataFrame
        """
        self._log("æ‰§è¡Œå…¨é¢æ’åä¿®å¤...")
        
        # ç¡®ä¿final_rankåˆ—å­˜åœ¨
        if 'final_rank' not in df.columns:
            df = self._create_emergency_rankings(df)
        
        # ç¡®ä¿final_rankæ˜¯æœ‰æ•ˆçš„æ•´æ•°
        df['final_rank'] = df['final_rank'].fillna(1).astype(int)
        
        # æœ€ç»ˆéªŒè¯å’Œä¿®å¤
        if 'ranker_id' in df.columns:
            problem_groups = 0
            total_groups = 0
            
            for ranker_id in df['ranker_id'].unique():
                total_groups += 1
                group_mask = df['ranker_id'] == ranker_id
                group_data = df[group_mask]
                group_size = len(group_data)
                
                current_ranks = sorted(group_data['final_rank'].values)
                expected_ranks = list(range(1, group_size + 1))
                
                if current_ranks != expected_ranks:
                    problem_groups += 1
                    
                    # æœ€ç»ˆå¼ºåˆ¶ä¿®å¤
                    final_seed = abs(hash(str(ranker_id) + "_final_fix")) % 1000000
                    np.random.seed(final_seed)
                    new_ranks = np.random.permutation(range(1, group_size + 1))
                    df.loc[group_mask, 'final_rank'] = new_ranks
            
            if problem_groups > 0:
                self._log(f"å…¨é¢ä¿®å¤å®Œæˆï¼šä¿®å¤äº† {problem_groups}/{total_groups} ä¸ªæœ€ç»ˆé—®é¢˜ç»„")
        
        # å°†final_rankå¤åˆ¶åˆ°selectedåˆ—ï¼ˆè¿™æ˜¯æœ€ç»ˆæäº¤éœ€è¦çš„åˆ—åï¼‰
        df['selected'] = df['final_rank']
        
        # ç¡®ä¿selectedåˆ—ä¹Ÿæ˜¯æ•´æ•°ç±»å‹
        df['selected'] = df['selected'].astype(int)
        
        # æœ€ç»ˆéªŒè¯
        if 'ranker_id' in df.columns:
            all_valid = True
            for ranker_id in df['ranker_id'].unique():
                group_mask = df['ranker_id'] == ranker_id
                group_data = df[group_mask]
                current_ranks = sorted(group_data['selected'].values)
                expected_ranks = list(range(1, len(group_data) + 1))
                
                if current_ranks != expected_ranks:
                    all_valid = False
                    self._log(f"âŒ æœ€ç»ˆéªŒè¯å¤±è´¥ ranker_id {ranker_id}: {current_ranks}")
            
            if all_valid:
                self._log("âœ… æœ€ç»ˆéªŒè¯é€šè¿‡ï¼Œæ‰€æœ‰æ’åéƒ½æ˜¯å”¯ä¸€ä¸”è¿ç»­çš„")
            else:
                self._log("âŒ æœ€ç»ˆéªŒè¯å¤±è´¥ï¼Œä»æœ‰æ’åé—®é¢˜")
        
        return df