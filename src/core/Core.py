"""
èˆªç­æ’åç³»ç»Ÿæ ¸å¿ƒæ§åˆ¶å™¨ - é›†æˆPyTorchç‰ˆæœ¬

è¯¥ç‰ˆæœ¬é›†æˆäº†PyTorchåˆ†æå™¨åŠŸèƒ½ï¼š
- æ”¯æŒé€‰æ‹©ä½¿ç”¨ä¼ ç»Ÿç‰ˆæœ¬æˆ–PyTorchç‰ˆæœ¬
- æ™ºèƒ½è·¯å¾„è¯†åˆ«å’Œæ¨¡å—å¯¼å…¥
- ç»Ÿä¸€çš„é…ç½®ç®¡ç†
- å‘åå…¼å®¹æ€§ä¿è¯

ä½œè€…: Flight Ranking Team
ç‰ˆæœ¬: 4.0 (PyTorché›†æˆç‰ˆ)
"""

import os
import sys
import logging
import warnings
from datetime import datetime
from typing import Dict, Any, Optional, List
from pathlib import Path

def setup_integrated_environment():
    """è®¾ç½®é›†æˆç¯å¢ƒ - æ”¯æŒPyTorchåˆ†æå™¨"""
    
    # è·å–å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
    current_file = Path(__file__).resolve()
    print(f"å½“å‰Core.pyæ–‡ä»¶: {current_file}")
    
    # é¡¹ç›®æ ¹ç›®å½•ï¼ˆFRç›®å½•ï¼‰
    project_root = current_file.parent.parent.parent
    print(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    
    # PyTorchåˆ†æå™¨ç›®å½•
    pytorch_analyzer_dir = project_root / "flight_ranking_analyzer pytorch"
    pytorch_src_dir = pytorch_analyzer_dir / "src"
    
    print(f"PyTorchåˆ†æå™¨ç›®å½•: {pytorch_analyzer_dir}")
    print(f"PyTorchæºç ç›®å½•: {pytorch_src_dir}")
    
    # æ£€æŸ¥PyTorchåˆ†æå™¨æ˜¯å¦å­˜åœ¨
    pytorch_available = pytorch_src_dir.exists()
    print(f"PyTorchåˆ†æå™¨å¯ç”¨: {pytorch_available}")
    
    # è®¾ç½®å·¥ä½œç›®å½•ä¸ºé¡¹ç›®æ ¹ç›®å½•
    os.chdir(project_root)
    print(f"å·¥ä½œç›®å½•è®¾ç½®ä¸º: {project_root}")
    
    # æ¸…ç†æ—§çš„è·¯å¾„
    paths_to_remove = []
    for path in sys.path[:]:
        if "GIT PROJECT\\FR" in path and path.count("\\") > 3:
            paths_to_remove.append(path)
    
    for path in paths_to_remove:
        if path in sys.path:
            sys.path.remove(path)
            print(f"ç§»é™¤æ—§è·¯å¾„: {path}")
    
    # æ·»åŠ æ­£ç¡®çš„è·¯å¾„ï¼ˆä¼ ç»Ÿç‰ˆæœ¬ï¼‰
    traditional_paths = [
        str(project_root),                           # E:\GIT PROJECT\FR
        str(project_root / "src"),                   # E:\GIT PROJECT\FR\src
        str(project_root / "src" / "core"),          # E:\GIT PROJECT\FR\src\core
        str(project_root / "src" / "data"),          # E:\GIT PROJECT\FR\src\data
        str(project_root / "src" / "model"),         # E:\GIT PROJECT\FR\src\model
        str(project_root / "src" / "utils"),         # E:\GIT PROJECT\FR\src\utils
    ]
    
    # æ·»åŠ PyTorchåˆ†æå™¨è·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    pytorch_paths = []
    if pytorch_available:
        pytorch_paths = [
            str(pytorch_analyzer_dir),               # E:\GIT PROJECT\FR\flight_ranking_analyzer pytorch
            str(pytorch_src_dir),                    # E:\GIT PROJECT\FR\flight_ranking_analyzer pytorch\src
        ]
    
    # åˆå¹¶æ‰€æœ‰è·¯å¾„ï¼ŒPyTorchè·¯å¾„ä¼˜å…ˆ
    all_paths = pytorch_paths + traditional_paths
    
    added_paths = []
    for path in all_paths:
        if Path(path).exists() and path not in sys.path:
            sys.path.insert(0, path)
            added_paths.append(path)
    
    print(f"æ·»åŠ è·¯å¾„: {added_paths}")
    
    return project_root, pytorch_available

def safe_import_modules():
    """å®‰å…¨å¯¼å…¥æ¨¡å— - ä¼˜å…ˆä½¿ç”¨PyTorchç‰ˆæœ¬"""
    imports_success = {}
    
    # æ£€æŸ¥PyTorchåˆ†æå™¨æ˜¯å¦å¯ç”¨
    pytorch_available = False
    try:
        # å°è¯•å¯¼å…¥PyTorchåˆ†æå™¨çš„config
        import config as pytorch_config
        if hasattr(pytorch_config, 'Config') and hasattr(pytorch_config.Config, 'PYTORCH_MODELS'):
            pytorch_available = True
            print("âœ“ æ£€æµ‹åˆ°PyTorchåˆ†æå™¨")
        else:
            pytorch_available = False
    except ImportError:
        pytorch_available = False
    
    # å®šä¹‰å¯¼å…¥é…ç½®
    import_configs = {
        'DataProcessor': [
            # PyTorchç‰ˆæœ¬ä¼˜å…ˆ
            ('data_processor', 'DataProcessor') if pytorch_available else None,
            # ä¼ ç»Ÿç‰ˆæœ¬å¤‡ç”¨
            ('DataProcessor', 'DataProcessor'),
            ('data.DataProcessor', 'DataProcessor'),
            ('src.data.DataProcessor', 'DataProcessor'),
        ],
        'FlightRankingTrainer': [
            # ä¼ ç»Ÿç‰ˆæœ¬
            ('Trainer', 'FlightRankingTrainer'),
            ('model.Trainer', 'FlightRankingTrainer'),
            ('src.model.Trainer', 'FlightRankingTrainer'),
        ],
        'FlightRankingPredictor': [
            # PyTorchç‰ˆæœ¬ä¼˜å…ˆ
            ('predictor', 'FlightRankingPredictor') if pytorch_available else None,
            # ä¼ ç»Ÿç‰ˆæœ¬å¤‡ç”¨
            ('Predictor', 'FlightRankingPredictor'),
            ('model.Predictor', 'FlightRankingPredictor'),
            ('src.model.Predictor', 'FlightRankingPredictor'),
        ],
        'FlightRankingAnalyzer': [
            # PyTorchç‰ˆæœ¬
            ('analyzer', 'FlightRankingAnalyzer') if pytorch_available else None,
        ],
        'ModelFactory': [
            # PyTorchç‰ˆæœ¬ä¼˜å…ˆ
            ('models', 'ModelFactory') if pytorch_available else None,
            # ä¼ ç»Ÿç‰ˆæœ¬å¤‡ç”¨
            ('Models', 'ModelFactory'),
            ('model.Models', 'ModelFactory'),
            ('src.model.Models', 'ModelFactory'),
        ],
        'FlightRankingModelsManager': [
            # ä¼ ç»Ÿç‰ˆæœ¬
            ('Manager', 'FlightRankingModelsManager'),
            ('model.Manager', 'FlightRankingModelsManager'),
            ('src.model.Manager', 'FlightRankingModelsManager'),
        ],
        'Config': [
            # PyTorchç‰ˆæœ¬ä¼˜å…ˆ
            ('config', 'Config') if pytorch_available else None,
        ],
        'AutoTuner': [
            # PyTorchç‰ˆæœ¬
            ('auto_tuner', 'AutoTuner') if pytorch_available else None,
        ]
    }
    
    # è¿‡æ»¤æ‰Noneå€¼
    for key in import_configs:
        import_configs[key] = [item for item in import_configs[key] if item is not None]
    
    # å°è¯•å¯¼å…¥æ¯ä¸ªæ¨¡å—
    for module_name, import_attempts in import_configs.items():
        imports_success[module_name] = None
        
        for module_path, class_name in import_attempts:
            try:
                print(f"å°è¯•å¯¼å…¥: from {module_path} import {class_name}")
                module = __import__(module_path, fromlist=[class_name])
                if hasattr(module, class_name):
                    imports_success[module_name] = getattr(module, class_name)
                    version = "PyTorchç‰ˆæœ¬" if pytorch_available and module_path in ['data_processor', 'predictor', 'analyzer', 'models', 'config', 'auto_tuner'] else "ä¼ ç»Ÿç‰ˆæœ¬"
                    print(f"âœ“ æˆåŠŸå¯¼å…¥ {module_name} ({version}) ä» {module_path}")
                    break
                else:
                    print(f"æ¨¡å— {module_path} ä¸­æ²¡æœ‰æ‰¾åˆ° {class_name}")
            except ImportError as e:
                print(f"å¯¼å…¥å¤±è´¥ {module_path}: {e}")
                continue
            except Exception as e:
                print(f"å¯¼å…¥å¼‚å¸¸ {module_path}: {e}")
                continue
        
        if imports_success[module_name] is None:
            print(f"âœ— æ— æ³•å¯¼å…¥ {module_name}")
    
    # å°è¯•å¯¼å…¥Commonå·¥å…·
    common_tools = None
    common_paths = [
        ('utils.Common', ['setup_logger', 'timer', 'memory_monitor', 'check_gpu_availability', 'ExperimentTracker', 'ConfigValidator']),
        ('Common', ['setup_logger', 'timer', 'memory_monitor', 'check_gpu_availability', 'ExperimentTracker', 'ConfigValidator']),
        ('src.utils.Common', ['setup_logger', 'timer', 'memory_monitor', 'check_gpu_availability', 'ExperimentTracker', 'ConfigValidator']),
    ]
    
    for module_path, required_attrs in common_paths:
        try:
            common_module = __import__(module_path, fromlist=required_attrs)
            common_tools = {}
            for attr in required_attrs:
                common_tools[attr] = getattr(common_module, attr, None)
            print(f"âœ“ æˆåŠŸå¯¼å…¥ Common å·¥å…·ä» {module_path}")
            break
        except ImportError as e:
            print(f"Commonå¯¼å…¥å¤±è´¥ {module_path}: {e}")
            continue
    
    if common_tools is None:
        print("âœ— æ— æ³•å¯¼å…¥ Common å·¥å…·ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
    
    imports_success['Common'] = common_tools
    imports_success['pytorch_available'] = pytorch_available
    return imports_success

# æ‰§è¡Œç¯å¢ƒè®¾ç½®
project_root, pytorch_available = setup_integrated_environment()

# å®‰å…¨å¯¼å…¥æ¨¡å—
imported_modules = safe_import_modules()

# å®šä¹‰ç®€åŒ–ç‰ˆæœ¬çš„å·¥å…·å‡½æ•°ï¼ˆå¦‚æœCommonå·¥å…·ä¸å¯ç”¨ï¼‰
if imported_modules['Common'] is None:
    def setup_logger(name, level="INFO"):
        logger = logging.getLogger(name)
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(getattr(logging, level.upper()))
        return logger
    
    def timer(func):
        import time
        from functools import wraps
        @wraps(func)
        def wrapper(*args, **kwargs):
            start = time.time()
            result = func(*args, **kwargs)
            end = time.time()
            print(f"{func.__name__} è€—æ—¶: {end-start:.2f}s")
            return result
        return wrapper
    
    def memory_monitor(func):
        from functools import wraps
        @wraps(func)
        def wrapper(*args, **kwargs):
            return func(*args, **kwargs)
        return wrapper
    
    def check_gpu_availability():
        """æ£€æŸ¥GPUå¯ç”¨æ€§"""
        gpu_info = {'cuda_available': False, 'device_count': 0, 'device_names': []}
        try:
            import torch
            gpu_info['cuda_available'] = torch.cuda.is_available()
            if gpu_info['cuda_available']:
                gpu_info['device_count'] = torch.cuda.device_count()
                gpu_info['device_names'] = [torch.cuda.get_device_name(i) for i in range(gpu_info['device_count'])]
        except ImportError:
            pass
        return gpu_info
    
    class ExperimentTracker:
        def __init__(self, experiment_name, output_dir):
            self.experiment_name = experiment_name
            self.output_dir = Path(output_dir)
            self.metrics = {}
            self.output_dir.mkdir(parents=True, exist_ok=True)
        
        def log_metric(self, name, value):
            self.metrics[name] = value
        
        def log_params(self, params):
            self.metrics.update(params)
        
        def save_results(self):
            import json
            result_file = self.output_dir / f"{self.experiment_name}_results.json"
            with open(result_file, 'w') as f:
                json.dump(self.metrics, f, indent=2, default=str)
            print(f"å®éªŒç»“æœå·²ä¿å­˜: {result_file}")
    
    class ConfigValidator:
        @staticmethod
        def validate_paths(config):
            errors = []
            if 'paths' in config:
                for key, path in config['paths'].items():
                    path_obj = Path(path)
                    if not path_obj.exists():
                        try:
                            path_obj.mkdir(parents=True, exist_ok=True)
                        except Exception as e:
                            errors.append(f"è·¯å¾„ä¸å­˜åœ¨ä¸”æ— æ³•åˆ›å»º: {key} = {path} ({e})")
            return errors
        
        @staticmethod
        def validate_model_config(config):
            errors = []
            if 'training' in config:
                required_keys = ['segments', 'model_names', 'use_gpu']
                for key in required_keys:
                    if key not in config['training']:
                        errors.append(f"ç¼ºå°‘è®­ç»ƒé…ç½®é¡¹: {key}")
            return errors
else:
    # ä½¿ç”¨å¯¼å…¥çš„Commonå·¥å…·
    common = imported_modules['Common']
    setup_logger = common['setup_logger'] or (lambda name, level="INFO": logging.getLogger(name))
    timer = common['timer'] or (lambda func: func)
    memory_monitor = common['memory_monitor'] or (lambda func: func)
    check_gpu_availability = common['check_gpu_availability'] or (lambda: {'cuda_available': False})
    ExperimentTracker = common['ExperimentTracker']
    ConfigValidator = common['ConfigValidator']

warnings.filterwarnings('ignore')


class SimplifiedDataProcessor:
    """ç®€åŒ–çš„æ•°æ®å¤„ç†å™¨"""
    def __init__(self, base_dir="data", **kwargs):
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(parents=True, exist_ok=True)
        print(f"ç®€åŒ–æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–: {self.base_dir}")
    
    def process_pipeline(self, force=False):
        print("æ‰§è¡Œç®€åŒ–æ•°æ®å¤„ç†æµç¨‹...")
        for subdir in ['processed', 'train', 'test']:
            (self.base_dir / subdir).mkdir(exist_ok=True)
        print("âœ“ ç®€åŒ–æ•°æ®å¤„ç†å®Œæˆ")
        return True


class SimplifiedTrainer:
    """ç®€åŒ–çš„è®­ç»ƒå™¨"""
    def __init__(self, config, logger=None):
        self.config = config
        self.logger = logger or logging.getLogger(__name__)
        print("ç®€åŒ–è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def train_all_segments(self):
        segments = self.config.get('training', {}).get('segments', [0, 1, 2])
        results = {}
        print(f"æ‰§è¡Œç®€åŒ–è®­ç»ƒæµç¨‹ï¼Œæ®µæ•°: {segments}")
        
        for segment_id in segments:
            results[f'segment_{segment_id}'] = {
                'status': 'completed',
                'validation_scores': {
                    'XGBRanker': 0.75,
                    'LGBMRanker': 0.73
                },
                'training_time': 10.0
            }
        
        print("âœ“ ç®€åŒ–è®­ç»ƒå®Œæˆ")
        return results


class SimplifiedPredictor:
    """ç®€åŒ–çš„é¢„æµ‹å™¨"""
    def __init__(self, config, logger=None):
        self.config = config
        self.logger = logger or logging.getLogger(__name__)
        print("ç®€åŒ–é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def predict_all_segments(self):
        import pandas as pd
        import numpy as np
        
        segments = self.config.get('prediction', {}).get('segments', [0, 1, 2])
        print(f"æ‰§è¡Œç®€åŒ–é¢„æµ‹æµç¨‹ï¼Œæ®µæ•°: {segments}")
        
        n_samples = 1000
        results = pd.DataFrame({
            'Id': range(1, n_samples + 1),
            'ranker_id': np.repeat(range(1, 101), 10),
            'selected': np.tile(range(1, 11), 100)
        })
        
        print(f"âœ“ ç®€åŒ–é¢„æµ‹å®Œæˆï¼Œç”Ÿæˆ {len(results)} æ¡è®°å½•")
        return results
    
    def validate_predictions(self, results):
        for ranker_id in results['ranker_id'].unique():
            group_data = results[results['ranker_id'] == ranker_id]
            expected_ranks = set(range(1, len(group_data) + 1))
            actual_ranks = set(group_data['selected'].values)
            if expected_ranks != actual_ranks:
                print(f"éªŒè¯å¤±è´¥: ranker_id {ranker_id}")
                return False
        print("âœ“ é¢„æµ‹ç»“æœéªŒè¯é€šè¿‡")
        return True


class FlightRankingCore:
    """èˆªç­æ’åç³»ç»Ÿæ ¸å¿ƒæ§åˆ¶å™¨ - PyTorché›†æˆç‰ˆæœ¬"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.project_root = project_root
        self.imported_modules = imported_modules
        self.pytorch_available = imported_modules.get('pytorch_available', False)
        
        # å†³å®šä½¿ç”¨çš„æ¨¡å¼
        self.use_pytorch_mode = self._determine_mode()
        
        self._setup_environment()
        self._setup_logging()
        self.logger = logging.getLogger(__name__)
        
        # éªŒè¯é…ç½®
        self._validate_config()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._init_components()
        
        # è®¾ç½®å®éªŒè¿½è¸ª
        self._setup_experiment_tracking()
        
        # è®¾ç½®æ€§èƒ½ç›‘æ§
        self._setup_performance_monitoring()
        
        self.logger.info(f"æ ¸å¿ƒæ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ (æ¨¡å¼: {'PyTorch' if self.use_pytorch_mode else 'ä¼ ç»Ÿ'})")
    
    def _determine_mode(self) -> bool:
        """å†³å®šä½¿ç”¨å“ªç§æ¨¡å¼"""
        # æ£€æŸ¥é…ç½®ä¸­çš„åå¥½
        mode_preference = self.config.get('mode', {}).get('prefer_pytorch', True)
        
        # æ£€æŸ¥PyTorchåˆ†æå™¨æ˜¯å¦å¯ç”¨
        pytorch_analyzer_available = self.imported_modules.get('FlightRankingAnalyzer') is not None
        
        # æ£€æŸ¥PyTorchç¯å¢ƒ
        pytorch_env_ok = False
        try:
            import torch
            pytorch_env_ok = True
        except ImportError:
            pytorch_env_ok = False
        
        use_pytorch = (
            mode_preference and 
            self.pytorch_available and 
            pytorch_analyzer_available and 
            pytorch_env_ok
        )
        
        mode_name = "PyTorché›†æˆæ¨¡å¼" if use_pytorch else "ä¼ ç»Ÿæ¨¡å¼"
        print(f"ğŸ¯ é€‰æ‹©è¿è¡Œæ¨¡å¼: {mode_name}")
        
        if use_pytorch:
            print("  âœ“ PyTorchåˆ†æå™¨å¯ç”¨")
            print("  âœ“ PyTorchç¯å¢ƒæ­£å¸¸")
        else:
            if not mode_preference:
                print("  - é…ç½®åå¥½: ä¼ ç»Ÿæ¨¡å¼")
            if not self.pytorch_available:
                print("  - PyTorchåˆ†æå™¨ä¸å¯ç”¨")
            if not pytorch_env_ok:
                print("  - PyTorchç¯å¢ƒä¸å¯ç”¨")
        
        return use_pytorch
    
    def _setup_environment(self):
        """è®¾ç½®å·¥ä½œç¯å¢ƒ"""
        for dir_key in ['data_dir', 'model_input_dir', 'model_save_dir', 'output_dir', 'log_dir']:
            if dir_key in self.config.get('paths', {}):
                dir_path = Path(self.config['paths'][dir_key])
                dir_path.mkdir(parents=True, exist_ok=True)
                print(f"ç¡®ä¿ç›®å½•å­˜åœ¨: {dir_path}")
    
    def _setup_logging(self):
        """è®¾ç½®å¢å¼ºæ—¥å¿—ç³»ç»Ÿ"""
        log_config = self.config.get('logging', {})
        log_dir = Path(self.config.get('paths', {}).get('log_dir', 'logs'))
        log_dir.mkdir(parents=True, exist_ok=True)
        
        log_file = log_dir / f"flight_ranking_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        mode_suffix = "pytorch" if self.use_pytorch_mode else "traditional"
        
        logging.basicConfig(
            level=getattr(logging, log_config.get('level', 'INFO').upper()),
            format=log_config.get('format', f'%(asctime)s - %(levelname)s - [{mode_suffix}] - %(message)s'),
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler(log_file, encoding='utf-8')
            ],
            force=True
        )
        
        print(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    def _validate_config(self):
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        try:
            validator = ConfigValidator()
            path_errors = validator.validate_paths(self.config)
            if path_errors:
                for error in path_errors:
                    print(f"é…ç½®è­¦å‘Š: {error}")
            
            model_errors = validator.validate_model_config(self.config)
            if model_errors:
                for error in model_errors:
                    print(f"é…ç½®è­¦å‘Š: {error}")
            
            print("é…ç½®éªŒè¯å®Œæˆ")
        except Exception as e:
            print(f"é…ç½®éªŒè¯å‡ºç°é—®é¢˜: {e}")
    
    def _init_components(self):
        """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""
        print(f"\nğŸ”§ åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶ ({'PyTorchæ¨¡å¼' if self.use_pytorch_mode else 'ä¼ ç»Ÿæ¨¡å¼'})")
        
        # æ•°æ®å¤„ç†å™¨
        if self.imported_modules['DataProcessor']:
            try:
                if self.use_pytorch_mode and 'data_processor' in str(type(self.imported_modules['DataProcessor']).__module__):
                    # PyTorchç‰ˆæœ¬çš„æ•°æ®å¤„ç†å™¨
                    self.data_processor = self.imported_modules['DataProcessor'](
                        logger=getattr(self, 'logger', None)
                    )
                    print("âœ“ PyTorchæ•°æ®å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
                else:
                    # ä¼ ç»Ÿç‰ˆæœ¬çš„æ•°æ®å¤„ç†å™¨
                    data_config = self.config.get('data_processing', {})
                    self.data_processor = self.imported_modules['DataProcessor'](
                        base_dir=self.config.get('paths', {}).get('data_dir', 'data'),
                        chunk_size=data_config.get('chunk_size', 200000),
                        n_processes=data_config.get('n_processes'),
                        logger=getattr(self, 'logger', None)
                    )
                    print("âœ“ ä¼ ç»Ÿæ•°æ®å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            except Exception as e:
                print(f"æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬: {e}")
                self.data_processor = SimplifiedDataProcessor(
                    base_dir=self.config.get('paths', {}).get('data_dir', 'data')
                )
        else:
            print("ä½¿ç”¨ç®€åŒ–æ•°æ®å¤„ç†å™¨")
            self.data_processor = SimplifiedDataProcessor(
                base_dir=self.config.get('paths', {}).get('data_dir', 'data')
            )
        
        # æ¨¡å‹ç»„ä»¶åˆå§‹åŒ–
        if self.use_pytorch_mode and self.imported_modules['FlightRankingAnalyzer']:
            # PyTorché›†æˆæ¨¡å¼
            self._init_pytorch_components()
        else:
            # ä¼ ç»Ÿæ¨¡å¼
            self._init_traditional_components()
        
        # æ˜¾ç¤ºGPUä¿¡æ¯
        gpu_info = check_gpu_availability()
        if gpu_info['cuda_available']:
            print(f"âœ“ GPUåŠ é€Ÿå¯ç”¨: {gpu_info}")
        else:
            print("ä½¿ç”¨CPUæ¨¡å¼")
    
    def _init_pytorch_components(self):
        """åˆå§‹åŒ–PyTorchç»„ä»¶"""
        print("ğŸ”¥ åˆå§‹åŒ–PyTorchç»„ä»¶...")
        
        try:
            # PyTorchåˆ†æå™¨
            training_config = self.config.get('training', {})
            self.pytorch_analyzer = self.imported_modules['FlightRankingAnalyzer'](
                use_gpu=training_config.get('use_gpu', True),
                logger=getattr(self, 'logger', None),
                selected_models=training_config.get('model_names', ['XGBRanker', 'LGBMRanker', 'NeuralRanker']),
                enable_auto_tuning=training_config.get('enable_auto_tuning', False),
                auto_tuning_trials=training_config.get('auto_tuning_trials', 50),
                save_models=training_config.get('save_models', True)
            )
            print("âœ“ PyTorchåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
            
            # PyTorché¢„æµ‹å™¨
            if self.imported_modules['FlightRankingPredictor']:
                self.model_predictor = self.imported_modules['FlightRankingPredictor'](
                    data_path=self.config.get('paths', {}).get('data_dir'),
                    use_gpu=training_config.get('use_gpu', True),
                    logger=getattr(self, 'logger', None)
                )
                print("âœ“ PyTorché¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
            
            # ä¼ ç»Ÿè®­ç»ƒå™¨ä½œä¸ºå¤‡ç”¨
            if self.imported_modules['FlightRankingTrainer']:
                self.model_trainer = self.imported_modules['FlightRankingTrainer'](
                    config=self.config,
                    logger=getattr(self, 'logger', None)
                )
                print("âœ“ ä¼ ç»Ÿè®­ç»ƒå™¨ä½œä¸ºå¤‡ç”¨åˆå§‹åŒ–å®Œæˆ")
            else:
                self.model_trainer = SimplifiedTrainer(self.config, getattr(self, 'logger', None))
            
        except Exception as e:
            print(f"PyTorchç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            print("å›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼...")
            self.use_pytorch_mode = False
            self._init_traditional_components()
    
    def _init_traditional_components(self):
        """åˆå§‹åŒ–ä¼ ç»Ÿç»„ä»¶"""
        print("ğŸ“Š åˆå§‹åŒ–ä¼ ç»Ÿç»„ä»¶...")
        
        # æ¨¡å‹è®­ç»ƒå™¨
        if self.imported_modules['FlightRankingTrainer']:
            try:
                self.model_trainer = self.imported_modules['FlightRankingTrainer'](
                    config=self.config,
                    logger=getattr(self, 'logger', None)
                )
                print("âœ“ ä¼ ç»Ÿæ¨¡å‹è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
            except Exception as e:
                print(f"ä¼ ç»Ÿæ¨¡å‹è®­ç»ƒå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬: {e}")
                self.model_trainer = SimplifiedTrainer(self.config, getattr(self, 'logger', None))
        else:
            print("ä½¿ç”¨ç®€åŒ–æ¨¡å‹è®­ç»ƒå™¨")
            self.model_trainer = SimplifiedTrainer(self.config, getattr(self, 'logger', None))
        
        # æ¨¡å‹é¢„æµ‹å™¨
        if self.imported_modules['FlightRankingPredictor']:
            try:
                self.model_predictor = self.imported_modules['FlightRankingPredictor'](
                    config=self.config,
                    logger=getattr(self, 'logger', None)
                )
                print("âœ“ ä¼ ç»Ÿæ¨¡å‹é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
            except Exception as e:
                print(f"ä¼ ç»Ÿæ¨¡å‹é¢„æµ‹å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬: {e}")
                self.model_predictor = SimplifiedPredictor(self.config, getattr(self, 'logger', None))
        else:
            print("ä½¿ç”¨ç®€åŒ–æ¨¡å‹é¢„æµ‹å™¨")
            self.model_predictor = SimplifiedPredictor(self.config, getattr(self, 'logger', None))
    
    def _setup_experiment_tracking(self):
        """è®¾ç½®å®éªŒè¿½è¸ª"""
        exp_config = self.config.get('experiment_tracking', {})
        
        if exp_config.get('enabled', False):
            try:
                experiment_name = exp_config.get('experiment_name', 'flight_ranking')
                if self.use_pytorch_mode:
                    experiment_name += "_pytorch"
                
                self.experiment_tracker = ExperimentTracker(
                    experiment_name=experiment_name,
                    output_dir=Path(self.config.get('paths', {}).get('output_dir', 'output'))
                )
                print("âœ“ å®éªŒè¿½è¸ªå·²å¯ç”¨")
            except Exception as e:
                print(f"å®éªŒè¿½è¸ªå¯ç”¨å¤±è´¥: {e}")
                self.experiment_tracker = None
        else:
            self.experiment_tracker = None
    
    def _setup_performance_monitoring(self):
        """è®¾ç½®æ€§èƒ½ç›‘æ§"""
        monitor_config = self.config.get('monitoring', {})
        
        if monitor_config.get('enabled', False):
            self.performance_metrics = {
                'start_time': datetime.now(),
                'mode': 'pytorch' if self.use_pytorch_mode else 'traditional',
                'training_times': {},
                'memory_usage': {},
                'model_scores': {},
                'system_resources': {}
            }
            print("âœ“ æ€§èƒ½ç›‘æ§å·²å¯ç”¨")
        else:
            self.performance_metrics = None
    
    @timer
    @memory_monitor
    def run_data_processing(self, force: bool = None) -> bool:
        """æ‰§è¡Œæ•°æ®å¤„ç†"""
        print(f"\nå¼€å§‹æ•°æ®å¤„ç†é˜¶æ®µ ({'PyTorchæ¨¡å¼' if self.use_pytorch_mode else 'ä¼ ç»Ÿæ¨¡å¼'})")
        
        try:
            data_config = self.config.get('data_processing', {})
            force = force if force is not None else data_config.get('force_reprocess', False)
            
            success = self.data_processor.process_pipeline(force=force)
            
            if success:
                print("âœ“ æ•°æ®å¤„ç†å®Œæˆ")
            else:
                print("âœ— æ•°æ®å¤„ç†å¤±è´¥")
            
            return success
        except Exception as e:
            print(f"æ•°æ®å¤„ç†å¼‚å¸¸: {e}")
            return False
    
    @timer
    @memory_monitor
    def run_model_training(self, segments: List[int] = None) -> bool:
        """æ‰§è¡Œæ¨¡å‹è®­ç»ƒ"""
        mode_name = "PyTorchæ¨¡å¼" if self.use_pytorch_mode else "ä¼ ç»Ÿæ¨¡å¼"
        print(f"\nå¼€å§‹æ¨¡å‹è®­ç»ƒé˜¶æ®µ ({mode_name})")
        
        try:
            if self.use_pytorch_mode and hasattr(self, 'pytorch_analyzer'):
                # ä½¿ç”¨PyTorchåˆ†æå™¨è¿›è¡Œè®­ç»ƒ
                return self._run_pytorch_training(segments)
            else:
                # ä½¿ç”¨ä¼ ç»Ÿè®­ç»ƒå™¨
                return self._run_traditional_training(segments)
        except Exception as e:
            print(f"æ¨¡å‹è®­ç»ƒå¼‚å¸¸: {e}")
            return False
    
    def _run_pytorch_training(self, segments: List[int] = None) -> bool:
        """è¿è¡ŒPyTorchè®­ç»ƒ"""
        print("ğŸ”¥ ä½¿ç”¨PyTorchåˆ†æå™¨è¿›è¡Œè®­ç»ƒ...")
        
        try:
            # è·å–è®­ç»ƒæ–‡ä»¶
            training_config = self.config.get('training', {})
            segments = segments or training_config.get('segments', [0, 1, 2])
            
            # è·å–PyTorché…ç½®
            pytorch_config = self.imported_modules.get('Config')
            if pytorch_config:
                train_files = pytorch_config.get_train_files()
                if not train_files:
                    print("æœªæ‰¾åˆ°è®­ç»ƒæ–‡ä»¶ï¼Œä½¿ç”¨ç®€åŒ–è®­ç»ƒ")
                    return self._run_traditional_training(segments)
                
                # å¯¹æ¯ä¸ªè®­ç»ƒæ–‡ä»¶æ‰§è¡Œåˆ†æ
                all_results = {}
                for i, train_file in enumerate(train_files[:len(segments)]):
                    print(f"\nè®­ç»ƒç¬¬ {i} æ®µ: {train_file}")
                    
                    # ä½¿ç”¨æŠ½æ ·å‚æ•°
                    use_sampling = training_config.get('use_sampling', True)
                    num_groups = training_config.get('num_groups', 2000)
                    min_group_size = training_config.get('min_group_size', 20)
                    
                    try:
                        result = self.pytorch_analyzer.full_analysis(
                            train_file,
                            use_sampling=use_sampling,
                            num_groups=num_groups,
                            min_group_size=min_group_size
                        )
                        all_results[f'segment_{i}'] = result
                        print(f"âœ“ ç¬¬ {i} æ®µè®­ç»ƒå®Œæˆ")
                    except Exception as e:
                        print(f"âœ— ç¬¬ {i} æ®µè®­ç»ƒå¤±è´¥: {e}")
                        continue
                
                success = len(all_results) > 0
                if success:
                    print("âœ“ PyTorchæ¨¡å‹è®­ç»ƒå®Œæˆ")
                    
                    # è®°å½•å®éªŒç»“æœ
                    if self.experiment_tracker:
                        self.experiment_tracker.log_params(training_config)
                        for segment, result in all_results.items():
                            if 'model_results' in result and result.get('model_results') is not None:
                                model_results = result['model_results']
                                if hasattr(model_results, 'iterrows'):
                                    for _, row in model_results.iterrows():
                                        self.experiment_tracker.log_metric(
                                            f"{segment}_{row['Model']}_hitrate", 
                                            row.get('HitRate@3', 0)
                                        )
                else:
                    print("âœ— PyTorchæ¨¡å‹è®­ç»ƒå¤±è´¥")
                
                return success
            else:
                print("æ— æ³•è·å–PyTorché…ç½®ï¼Œå›é€€åˆ°ä¼ ç»Ÿè®­ç»ƒ")
                return self._run_traditional_training(segments)
                
        except Exception as e:
            print(f"PyTorchè®­ç»ƒå¼‚å¸¸: {e}")
            print("å›é€€åˆ°ä¼ ç»Ÿè®­ç»ƒ...")
            return self._run_traditional_training(segments)
    
    def _run_traditional_training(self, segments: List[int] = None) -> bool:
        """è¿è¡Œä¼ ç»Ÿè®­ç»ƒ"""
        print("ğŸ“Š ä½¿ç”¨ä¼ ç»Ÿè®­ç»ƒå™¨è¿›è¡Œè®­ç»ƒ...")
        
        try:
            training_config = self.config.get('training', {})
            segments = segments or training_config.get('segments', [0, 1, 2])
            
            results = self.model_trainer.train_all_segments()
            
            success = len(results) > 0
            if success:
                print("âœ“ ä¼ ç»Ÿæ¨¡å‹è®­ç»ƒå®Œæˆ")
                
                if self.experiment_tracker:
                    self.experiment_tracker.log_params(training_config)
                    for segment, result in results.items():
                        if 'validation_scores' in result:
                            for model, score in result['validation_scores'].items():
                                self.experiment_tracker.log_metric(f"{segment}_{model}_score", score)
            else:
                print("âœ— ä¼ ç»Ÿæ¨¡å‹è®­ç»ƒå¤±è´¥")
            
            return success
            
        except Exception as e:
            print(f"ä¼ ç»Ÿè®­ç»ƒå¼‚å¸¸: {e}")
            return False
    
    @timer
    @memory_monitor
    def run_model_prediction(self, segments: List[int] = None, 
                           model_names: List[str] = None) -> bool:
        """æ‰§è¡Œæ¨¡å‹é¢„æµ‹"""
        mode_name = "PyTorchæ¨¡å¼" if self.use_pytorch_mode else "ä¼ ç»Ÿæ¨¡å¼"
        print(f"\nå¼€å§‹æ¨¡å‹é¢„æµ‹é˜¶æ®µ ({mode_name})")
        
        try:
            prediction_config = self.config.get('prediction', {})
            segments = segments or prediction_config.get('segments', [0, 1, 2])
            model_names = model_names or prediction_config.get('model_names', ['XGBRanker', 'LGBMRanker'])
            
            if self.use_pytorch_mode and hasattr(self, 'pytorch_analyzer'):
                # ä½¿ç”¨PyTorchåˆ†æå™¨è¿›è¡Œé¢„æµ‹
                return self._run_pytorch_prediction(segments, model_names)
            else:
                # ä½¿ç”¨ä¼ ç»Ÿé¢„æµ‹å™¨
                return self._run_traditional_prediction(segments, model_names)
                
        except Exception as e:
            print(f"æ¨¡å‹é¢„æµ‹å¼‚å¸¸: {e}")
            return False
    
    def _run_pytorch_prediction(self, segments: List[int], model_names: List[str]) -> bool:
        """è¿è¡ŒPyTorché¢„æµ‹"""
        print("ğŸ”¥ ä½¿ç”¨PyTorché¢„æµ‹å™¨è¿›è¡Œé¢„æµ‹...")
        
        try:
            # è·å–PyTorché…ç½®
            pytorch_config = self.imported_modules.get('Config')
            if pytorch_config:
                test_files = pytorch_config.get_test_files()
                if not test_files:
                    print("æœªæ‰¾åˆ°æµ‹è¯•æ–‡ä»¶ï¼Œä½¿ç”¨ç®€åŒ–é¢„æµ‹")
                    return self._run_traditional_prediction(segments, model_names)
                
                # ä½¿ç”¨ä¿å­˜çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
                if hasattr(self.model_predictor, 'predict_all'):
                    result = self.model_predictor.predict_all(
                        segments=segments,
                        model_names=model_names,
                        ensemble_method='average'
                    )
                    
                    success = result is not None and len(result) > 0
                    if success:
                        print(f"âœ“ PyTorché¢„æµ‹å®Œæˆï¼Œè®°å½•æ•°: {len(result)}")
                        
                        # éªŒè¯é¢„æµ‹ç»“æœ
                        self.model_predictor.validate_predictions(result)
                        
                        # ä¿å­˜ç»“æœ
                        output_dir = Path(self.config.get('paths', {}).get('output_dir', 'output'))
                        output_file = output_dir / "pytorch_submission.csv"
                        result.to_csv(output_file, index=False)
                        print(f"âœ“ é¢„æµ‹ç»“æœå·²ä¿å­˜: {output_file}")
                        
                    else:
                        print("âœ— PyTorché¢„æµ‹å¤±è´¥")
                    
                    return success
                else:
                    print("é¢„æµ‹å™¨ä¸æ”¯æŒæ‰¹é‡é¢„æµ‹ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•")
                    return self._run_traditional_prediction(segments, model_names)
            else:
                print("æ— æ³•è·å–PyTorché…ç½®ï¼Œå›é€€åˆ°ä¼ ç»Ÿé¢„æµ‹")
                return self._run_traditional_prediction(segments, model_names)
                
        except Exception as e:
            print(f"PyTorché¢„æµ‹å¼‚å¸¸: {e}")
            print("å›é€€åˆ°ä¼ ç»Ÿé¢„æµ‹...")
            return self._run_traditional_prediction(segments, model_names)
    
    def _run_traditional_prediction(self, segments: List[int], model_names: List[str]) -> bool:
        """è¿è¡Œä¼ ç»Ÿé¢„æµ‹"""
        print("ğŸ“Š ä½¿ç”¨ä¼ ç»Ÿé¢„æµ‹å™¨è¿›è¡Œé¢„æµ‹...")
        
        try:
            results = self.model_predictor.predict_all_segments()
            
            success = results is not None and len(results) > 0
            if success:
                print(f"âœ“ ä¼ ç»Ÿé¢„æµ‹å®Œæˆï¼Œè®°å½•æ•°: {len(results)}")
                
                validation_success = self.model_predictor.validate_predictions(results)
                if validation_success:
                    print("âœ“ é¢„æµ‹ç»“æœéªŒè¯é€šè¿‡")
                else:
                    print("âš  é¢„æµ‹ç»“æœéªŒè¯æœªå®Œå…¨é€šè¿‡")
                
                output_dir = Path(self.config.get('paths', {}).get('output_dir', 'output'))
                output_file = output_dir / "traditional_submission.csv"
                results.to_csv(output_file, index=False)
                print(f"âœ“ é¢„æµ‹ç»“æœå·²ä¿å­˜: {output_file}")
                
            else:
                print("âœ— ä¼ ç»Ÿé¢„æµ‹å¤±è´¥")
            
            return success
            
        except Exception as e:
            print(f"ä¼ ç»Ÿé¢„æµ‹å¼‚å¸¸: {e}")
            return False
    
    def run_full_pipeline(self, skip_data: bool = False, 
                         skip_training: bool = False, 
                         skip_prediction: bool = False) -> bool:
        """æ‰§è¡Œå®Œæ•´æµæ°´çº¿"""
        mode_name = "PyTorché›†æˆæ¨¡å¼" if self.use_pytorch_mode else "ä¼ ç»Ÿæ¨¡å¼"
        print("=" * 60)
        print(f"å¼€å§‹å®Œæ•´æµæ°´çº¿æ‰§è¡Œ ({mode_name})")
        print("=" * 60)
        
        start_time = datetime.now()
        pipeline_config = self.config.get('pipeline', {})
        
        try:
            # æ•°æ®å¤„ç†
            if not skip_data and pipeline_config.get('run_data_processing', True):
                print("\n" + "="*50)
                print("ç¬¬1æ­¥: æ•°æ®å¤„ç†")
                print("="*50)
                if not self.run_data_processing():
                    print("æ•°æ®å¤„ç†å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤")
            else:
                print("è·³è¿‡æ•°æ®å¤„ç†")
            
            # æ¨¡å‹è®­ç»ƒ
            if not skip_training and pipeline_config.get('run_training', True):
                print("\n" + "="*50)
                print("ç¬¬2æ­¥: æ¨¡å‹è®­ç»ƒ")
                print("="*50)
                if not self.run_model_training():
                    print("æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤")
            else:
                print("è·³è¿‡æ¨¡å‹è®­ç»ƒ")
            
            # æ¨¡å‹é¢„æµ‹
            if not skip_prediction and pipeline_config.get('run_prediction', True):
                print("\n" + "="*50)
                print("ç¬¬3æ­¥: æ¨¡å‹é¢„æµ‹")
                print("="*50)
                if not self.run_model_prediction():
                    print("æ¨¡å‹é¢„æµ‹å¤±è´¥")
                    return False
            else:
                print("è·³è¿‡æ¨¡å‹é¢„æµ‹")
            
            total_time = datetime.now() - start_time
            
            if self.experiment_tracker:
                self.experiment_tracker.log_metric('total_time', total_time.total_seconds())
                self.experiment_tracker.log_metric('mode', 'pytorch' if self.use_pytorch_mode else 'traditional')
                self.experiment_tracker.save_results()
            
            print("\n" + "="*60)
            print(f"âœ“ å®Œæ•´æµæ°´çº¿æ‰§è¡ŒæˆåŠŸ ({mode_name})ï¼Œè€—æ—¶: {total_time}")
            print("="*60)
            return True
            
        except Exception as e:
            print(f"æµæ°´çº¿æ‰§è¡Œå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return {
            'mode': 'pytorch' if self.use_pytorch_mode else 'traditional',
            'project_root': str(self.project_root),
            'pytorch_available': self.pytorch_available,
            'available_components': {
                'data_processor': self.data_processor is not None,
                'model_trainer': self.model_trainer is not None,
                'model_predictor': self.model_predictor is not None,
                'pytorch_analyzer': hasattr(self, 'pytorch_analyzer') and self.pytorch_analyzer is not None,
            },
            'imported_modules': {
                name: module is not None 
                for name, module in self.imported_modules.items()
                if name not in ['Common', 'pytorch_available']
            },
            'gpu_available': check_gpu_availability().get('cuda_available', False),
            'python_paths': [p for p in sys.path if any(keyword in p.lower() for keyword in ['src', 'fr', 'flight'])],
            'working_directory': str(Path.cwd()),
        }
    
    def run_minimal_test(self) -> bool:
        """è¿è¡Œæœ€å°æµ‹è¯•ï¼ŒéªŒè¯ç³»ç»ŸåŸºæœ¬åŠŸèƒ½"""
        mode_name = "PyTorché›†æˆæ¨¡å¼" if self.use_pytorch_mode else "ä¼ ç»Ÿæ¨¡å¼"
        print(f"å¼€å§‹ç³»ç»ŸåŸºæœ¬åŠŸèƒ½æµ‹è¯• ({mode_name})...")
        
        try:
            # æµ‹è¯•é…ç½®
            assert self.config is not None, "é…ç½®ä¸èƒ½ä¸ºç©º"
            print("âœ“ é…ç½®æµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•è·¯å¾„
            for path_key, path_value in self.config.get('paths', {}).items():
                path = Path(path_value)
                if not path.exists():
                    path.mkdir(parents=True, exist_ok=True)
                assert path.exists(), f"è·¯å¾„åˆ›å»ºå¤±è´¥: {path}"
            print("âœ“ è·¯å¾„æµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•GPUæ£€æµ‹
            gpu_info = check_gpu_availability()
            print(f"âœ“ GPUæ£€æµ‹å®Œæˆ: {gpu_info}")
            
            # æµ‹è¯•æ—¥å¿—
            if hasattr(self, 'logger'):
                self.logger.info("æ—¥å¿—ç³»ç»Ÿæµ‹è¯•")
                print("âœ“ æ—¥å¿—ç³»ç»Ÿæµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•ç»„ä»¶
            components = ['data_processor', 'model_trainer', 'model_predictor']
            for component in components:
                if hasattr(self, component) and getattr(self, component) is not None:
                    print(f"âœ“ {component} å¯ç”¨")
                else:
                    print(f"âš  {component} ä¸å¯ç”¨")
            
            # æµ‹è¯•PyTorchç»„ä»¶
            if self.use_pytorch_mode:
                if hasattr(self, 'pytorch_analyzer') and self.pytorch_analyzer is not None:
                    print("âœ“ PyTorchåˆ†æå™¨å¯ç”¨")
                else:
                    print("âš  PyTorchåˆ†æå™¨ä¸å¯ç”¨")
            
            print(f"âœ“ ç³»ç»ŸåŸºæœ¬åŠŸèƒ½æµ‹è¯•å…¨éƒ¨é€šè¿‡ ({mode_name})")
            return True
            
        except Exception as e:
            print(f"âœ— ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def switch_mode(self, use_pytorch: bool = None):
        """åˆ‡æ¢è¿è¡Œæ¨¡å¼"""
        if use_pytorch is None:
            use_pytorch = not self.use_pytorch_mode
        
        if use_pytorch == self.use_pytorch_mode:
            print(f"å·²ç»æ˜¯{'PyTorch' if use_pytorch else 'ä¼ ç»Ÿ'}æ¨¡å¼")
            return
        
        print(f"åˆ‡æ¢æ¨¡å¼: {'ä¼ ç»Ÿ' if self.use_pytorch_mode else 'PyTorch'} â†’ {'PyTorch' if use_pytorch else 'ä¼ ç»Ÿ'}")
        
        # æ£€æŸ¥åˆ‡æ¢çš„å¯è¡Œæ€§
        if use_pytorch and not self.pytorch_available:
            print("âŒ æ— æ³•åˆ‡æ¢åˆ°PyTorchæ¨¡å¼ï¼šPyTorchåˆ†æå™¨ä¸å¯ç”¨")
            return
        
        # æ‰§è¡Œåˆ‡æ¢
        self.use_pytorch_mode = use_pytorch
        
        # é‡æ–°åˆå§‹åŒ–ç»„ä»¶
        print("é‡æ–°åˆå§‹åŒ–ç»„ä»¶...")
        self._init_components()
        
        print(f"âœ“ å·²åˆ‡æ¢åˆ°{'PyTorch' if use_pytorch else 'ä¼ ç»Ÿ'}æ¨¡å¼")


def main():
    """ä¸»å‡½æ•° - ç”¨äºç›´æ¥è¿è¡ŒCore.pyæ—¶æµ‹è¯•"""
    print("=" * 60)
    print("èˆªç­æ’åç³»ç»Ÿæ ¸å¿ƒæ§åˆ¶å™¨æµ‹è¯• - PyTorché›†æˆç‰ˆ")
    print("=" * 60)
    
    # åŸºæœ¬é…ç½®
    test_config = {
        'mode': {
            'prefer_pytorch': True,  # ä¼˜å…ˆä½¿ç”¨PyTorchæ¨¡å¼
        },
        'paths': {
            'data_dir': 'data',
            'model_input_dir': 'data/processed',
            'model_save_dir': 'models',
            'output_dir': 'output',
            'log_dir': 'logs'
        },
        'data_processing': {
            'chunk_size': 200000,
            'n_processes': None,
            'force_reprocess': False,
            'use_sampling': True,
            'num_groups': 2000,
            'min_group_size': 20
        },
        'training': {
            'segments': [0, 1, 2],
            'model_names': ['XGBRanker', 'LGBMRanker', 'NeuralRanker'],
            'use_gpu': True,
            'random_state': 42,
            'enable_auto_tuning': False,
            'auto_tuning_trials': 50,
            'save_models': True
        },
        'prediction': {
            'segments': [0, 1, 2],
            'model_names': ['XGBRanker', 'LGBMRanker', 'NeuralRanker'],
            'use_gpu': True,
            'enable_business_rules': False
        },
        'pipeline': {
            'run_data_processing': True,
            'run_training': True,
            'run_prediction': True
        },
        'experiment_tracking': {
            'enabled': True,
            'experiment_name': 'test_run'
        },
        'logging': {
            'level': 'INFO'
        }
    }
    
    try:
        print("åˆå§‹åŒ–é›†æˆæ ¸å¿ƒæ§åˆ¶å™¨...")
        core = FlightRankingCore(test_config)
        
        print("\nè·å–ç³»ç»ŸçŠ¶æ€...")
        status = core.get_status()
        print("\nç³»ç»ŸçŠ¶æ€:")
        for key, value in status.items():
            print(f"  {key}: {value}")
        
        print("\nè¿è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•...")
        test_result = core.run_minimal_test()
        
        if test_result:
            print("\n" + "="*60)
            print("âœ“ æ ¸å¿ƒæ§åˆ¶å™¨æµ‹è¯•æˆåŠŸ")
            print("="*60)
            
            # è¯¢é—®æ˜¯å¦è¿è¡Œå®Œæ•´æµæ°´çº¿
            try:
                response = input("\næ˜¯å¦è¿è¡Œå®Œæ•´æµæ°´çº¿æµ‹è¯•? (y/N): ").strip().lower()
                if response in ['y', 'yes']:
                    print("\nå¼€å§‹è¿è¡Œå®Œæ•´æµæ°´çº¿...")
                    pipeline_result = core.run_full_pipeline()
                    if pipeline_result:
                        print("âœ“ å®Œæ•´æµæ°´çº¿æµ‹è¯•æˆåŠŸ")
                    else:
                        print("âš  å®Œæ•´æµæ°´çº¿æµ‹è¯•éƒ¨åˆ†æˆåŠŸ")
                else:
                    print("è·³è¿‡å®Œæ•´æµæ°´çº¿æµ‹è¯•")
                
                # è¯¢é—®æ˜¯å¦åˆ‡æ¢æ¨¡å¼æµ‹è¯•
                if core.pytorch_available:
                    response = input("\næ˜¯å¦æµ‹è¯•æ¨¡å¼åˆ‡æ¢åŠŸèƒ½? (y/N): ").strip().lower()
                    if response in ['y', 'yes']:
                        core.switch_mode()
                        core.run_minimal_test()
                        
            except (KeyboardInterrupt, EOFError):
                print("\nè·³è¿‡äº¤äº’æµ‹è¯•")
            
            return True
        else:
            print("\n" + "="*60)  
            print("âœ— æ ¸å¿ƒæ§åˆ¶å™¨æµ‹è¯•å¤±è´¥")
            print("="*60)
            return False
        
    except Exception as e:
        print(f"\nâœ— æ ¸å¿ƒæ§åˆ¶å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)