#!/usr/bin/env python3

"""
èˆªç­æ’åç³»ç»Ÿä¸»å…¥å£ - é«˜æ•ˆä¼˜åŒ–ç‰ˆ
ä¸»è¦ä¼˜åŒ–ï¼š
1. ç®€åŒ–å¯åŠ¨æµç¨‹ï¼Œå»é™¤ä¸å¿…è¦çš„æ£€æŸ¥
2. ç›´æ¥GPUåˆå§‹åŒ–ï¼Œå‡å°‘é¢„çƒ­æ—¶é—´
3. æœ€å°åŒ–ç¯å¢ƒè®¾ç½®
4. å¿«é€Ÿè·¯å¾„é…ç½®
"""

import os
import sys
import time
import warnings
from pathlib import Path

# ==================== ç®€åŒ–ç¯å¢ƒè®¾ç½® ====================
def setup_environment_fast():
    """å¿«é€Ÿç¯å¢ƒè®¾ç½®"""
    warnings.filterwarnings('ignore')
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
    os.environ['PYTHONWARNINGS'] = 'ignore'
    
    # GPUè®¾ç½®
    os.environ['CUDA_LAUNCH_BLOCKING'] = '0'
    os.environ['OMP_NUM_THREADS'] = str(min(os.cpu_count(), 8))

def setup_python_path_fast():
    """å¿«é€Ÿè®¾ç½®Pythonè·¯å¾„"""
    current_file = Path(__file__).resolve()
    
    if current_file.parent.name == 'src':
        project_root = current_file.parent.parent
    else:
        project_root = current_file.parent
    
    sys.path.insert(0, str(project_root))
    sys.path.insert(0, str(project_root / "src"))
    
    os.chdir(project_root)
    return project_root

def check_gpu_fast():
    """å¿«é€ŸGPUæ£€æŸ¥"""
    try:
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            print(f"âœ“ GPUå¯ç”¨: {gpu_name}")
            
            # ç®€å•é¢„çƒ­ï¼Œé¿å…å¤æ‚çš„é¢„çƒ­æ“ä½œ
            device = torch.device('cuda:0')
            x = torch.randn(100, 100, device=device)
            y = torch.matmul(x, x.t())
            del x, y
            torch.cuda.empty_cache()
            
            return True
    except Exception:
        pass
    print("âš ï¸ GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
    return False

def import_core_fast():
    """å¿«é€Ÿå¯¼å…¥æ ¸å¿ƒæ¨¡å—"""
    try:
        from src.core.Core import FlightRankingCore
        return FlightRankingCore
    except ImportError:
        try:
            from core.Core import FlightRankingCore
            return FlightRankingCore
        except ImportError:
            raise ImportError("æ— æ³•å¯¼å…¥FlightRankingCoreæ¨¡å—")

def create_fast_config():
    """åˆ›å»ºå¿«é€Ÿé…ç½® - é’ˆå¯¹é«˜æ•ˆè®­ç»ƒä¼˜åŒ–"""
    return {
        'paths': {
            'data_dir': "data/aeroclub-recsys-2025",
            'model_input_dir': "data/aeroclub-recsys-2025/processed",
            'model_save_dir': "data/aeroclub-recsys-2025/models",
            'output_dir': "data/aeroclub-recsys-2025/submissions",
            'log_dir': "logs"
        },
        'data_processing': {
            'chunk_size': 500000,  # å¤§å—å¤„ç†æå‡æ•ˆç‡
            'n_processes': min(os.cpu_count(), 4),  # é€‚ä¸­çš„è¿›ç¨‹æ•°
            'force_reprocess': False
        },
        'training': {
            'segments': [0, 1, 2],
            'model_names': ['XGBRanker', 'LGBMRanker', 'LambdaMART'],
            'use_gpu': True,
            'random_state': 42,
            'use_full_data': True,  # å¯ç”¨å…¨é‡æ•°æ®æ¨¡å¼
            'model_configs': {
                'XGBRanker': {
                    'n_estimators': 100,
                    'max_depth': 6,
                    'learning_rate': 0.1,
                    'subsample': 0.8,
                    'colsample_bytree': 0.8,
                    'verbosity': 0
                },
                'LGBMRanker': {
                    'n_estimators': 100,
                    'max_depth': 6,
                    'learning_rate': 0.1,
                    'subsample': 0.8,
                    'colsample_bytree': 0.8,
                    'verbose': -1
                },
                'LambdaMART': {
                    'n_estimators': 100,
                    'max_depth': 6,
                    'learning_rate': 0.1
                }
            }
        },
        'prediction': {
            'segments': [0, 1, 2],
            'model_names': ['XGBRanker', 'LGBMRanker', 'LambdaMART'],
            'use_gpu': True,
        },
        'pipeline': {
            'run_data_processing': False,  # è·³è¿‡æ•°æ®å¤„ç†åŠ å¿«å¯åŠ¨
            'run_training': True,
            'run_prediction': True
        },
        'logging': {
            'level': "INFO",
            'format': "%(asctime)s | %(levelname)8s | %(message)s"
        }
    }

def load_config_fast():
    """å¿«é€ŸåŠ è½½é…ç½®"""
    try:
        import yaml
        config_path = Path("config/conf.yaml")
        
        if config_path.exists():
            print("ğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶...")
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # åº”ç”¨é«˜æ•ˆä¼˜åŒ–
            if 'training' in config:
                # ç¡®ä¿ä½¿ç”¨å…¨é‡æ•°æ®æ¨¡å¼ä»¥è·å¾—æœ€ä½³æ€§èƒ½
                config['training']['use_full_data'] = True
                
                # ä¼˜åŒ–æ¨¡å‹å‚æ•°ä»¥æå‡è®­ç»ƒé€Ÿåº¦
                if 'model_configs' in config['training']:
                    for model_name, model_config in config['training']['model_configs'].items():
                        if model_name in ['XGBRanker', 'LGBMRanker', 'LambdaMART']:
                            model_config.update({
                                'verbosity': 0,
                                'verbose': -1,
                                'n_jobs': -1
                            })
            
            print("âœ“ é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
            return config
        else:
            print("âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨å¿«é€Ÿé»˜è®¤é…ç½®")
            return create_fast_config()
    except Exception as e:
        print(f"âš ï¸ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return create_fast_config()

def show_system_info_fast():
    """æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯ - ç®€åŒ–ç‰ˆ"""
    import psutil
    
    print("\n" + "="*50)
    print("ğŸ–¥ï¸  ç³»ç»Ÿä¿¡æ¯")
    print("="*50)
    print(f"CPUæ ¸å¿ƒæ•°: {os.cpu_count()}")
    print(f"å¯ç”¨å†…å­˜: {psutil.virtual_memory().available // (1024**3)}GB")
    
    try:
        import torch
        if torch.cuda.is_available():
            print(f"GPU: {torch.cuda.get_device_name(0)}")
            print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory // (1024**3)}GB")
        else:
            print("GPU: ä¸å¯ç”¨")
    except:
        print("GPU: æ£€æŸ¥å¤±è´¥")
    print("="*50 + "\n")

def main():
    """ä¸»å‡½æ•° - é«˜æ•ˆä¼˜åŒ–ç‰ˆ"""
    total_start = time.time()
    
    print("="*60)
    print("ğŸš€ èˆªç­æ’åç³»ç»Ÿå¯åŠ¨ - é«˜æ•ˆä¼˜åŒ–ç‰ˆ")
    print("="*60)
    
    try:
        # 1. å¿«é€Ÿç¯å¢ƒè®¾ç½®
        setup_environment_fast()
        
        # 2. è·¯å¾„è®¾ç½®
        project_root = setup_python_path_fast()
        print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
        
        # 3. æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
        show_system_info_fast()
        
        # 4. GPUæ£€æŸ¥å’Œé¢„çƒ­
        gpu_ready = check_gpu_fast()
        
        # 5. å¯¼å…¥æ ¸å¿ƒæ¨¡å—
        print("ğŸ“¦ å¯¼å…¥æ ¸å¿ƒæ¨¡å—...")
        import_start = time.time()
        FlightRankingCore = import_core_fast()
        import_time = time.time() - import_start
        print(f"âœ“ æ ¸å¿ƒæ¨¡å—å¯¼å…¥å®Œæˆ (è€—æ—¶: {import_time:.2f}s)")
        
        # 6. åŠ è½½é…ç½®
        config = load_config_fast()
        
        # 7. ç³»ç»Ÿåˆå§‹åŒ–
        print("âš™ï¸ åˆå§‹åŒ–ç³»ç»Ÿ...")
        init_start = time.time()
        
        core = FlightRankingCore(config)
        init_time = time.time() - init_start
        print(f"âœ“ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ (è€—æ—¶: {init_time:.2f}s)")
        
        # 8. æ˜¾ç¤ºå¯åŠ¨ç»Ÿè®¡
        startup_time = time.time() - total_start
        print(f"\nğŸ¯ ç³»ç»Ÿå¯åŠ¨å®Œæˆ! æ€»è€—æ—¶: {startup_time:.2f}s")
        print(f"ğŸ’¡ ä¼˜åŒ–çŠ¶æ€: GPU {'âœ“' if gpu_ready else 'âœ—'}, å…¨é‡æ•°æ®æ¨¡å¼ {'âœ“' if config.get('training', {}).get('use_full_data') else 'âœ—'}")
        
        # 9. è¿è¡Œæµæ°´çº¿
        print("\n" + "="*60)
        print("ğŸƒ å¼€å§‹æ‰§è¡Œæµæ°´çº¿...")
        print("="*60)
        
        pipeline_start = time.time()
        success = core.run_full_pipeline()
        pipeline_time = time.time() - pipeline_start
        
        if success:
            print("\n" + "="*60)
            print("âœ… èˆªç­æ’åç³»ç»Ÿæ‰§è¡ŒæˆåŠŸ!")
            print(f"ğŸ“Š æµæ°´çº¿è€—æ—¶: {pipeline_time:.2f}s")
            print(f"ğŸ¯ æ€»è€—æ—¶: {time.time() - total_start:.2f}s")
            print("="*60)
        else:
            print("\n" + "="*60)
            print("âŒ èˆªç­æ’åç³»ç»Ÿæ‰§è¡Œå¤±è´¥")
            print("="*60)
        
        return 0 if success else 1
        
    except KeyboardInterrupt:
        print("\nâ¸ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        return 1
    except Exception as e:
        print(f"\nğŸ’¥ ç³»ç»Ÿè¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)