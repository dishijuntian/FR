"""
æ”¹è¿›çš„èˆªç­æ’åºé¢„æµ‹å™¨ - PyTorchç‰ˆæœ¬

åŸºäºæ›´ä¼˜ç§€çš„é¢„æµ‹ä»£ç ç»“æ„é‡æ–°è®¾è®¡ï¼Œæä¾›ï¼š
- ç®€åŒ–äº†æ’åå¤„ç†é€»è¾‘
- ç§»é™¤äº†å¤æ‚çš„åˆ†æ‰¹éªŒè¯å¤„ç†
- ä½¿ç”¨ç®€å•é«˜æ•ˆçš„æ’ååˆ†é…æ–¹æ³•
- æ”¯æŒPyTorchæ¨¡å‹çš„ä¿å­˜å’ŒåŠ è½½

ä½œè€…: Flight Ranking Team
ç‰ˆæœ¬: 3.3 (PyTorchç‰ˆæœ¬)
"""

import pandas as pd
import numpy as np
import joblib
import torch
import torch.nn as nn
import os
from pathlib import Path
from typing import List, Optional, Dict, Any, Tuple
import warnings
import gc
import psutil
import pickle

# å¯¼å…¥åŸæœ‰æ¨¡å—
try:
    from .config import Config
    from .models import ModelFactory
    from .data_processor import DataProcessor
    from .progress_utils import progress_bar, create_data_loading_progress
except ImportError:
    from config import Config
    from models import ModelFactory
    from data_processor import DataProcessor
    from progress_utils import progress_bar, create_data_loading_progress

warnings.filterwarnings('ignore')

# PyTorchè®¾å¤‡è®¾ç½®
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


class FlightRankingPredictor:
    """æ”¹è¿›çš„èˆªç­æ’åºé¢„æµ‹å™¨ - PyTorchç‰ˆæœ¬"""
    
    def __init__(self, 
                 data_path: str = None,
                 model_save_path: str = "models", 
                 output_path: str = "submissions",
                 use_gpu: bool = False, 
                 random_state: int = 42,
                 logger=None):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        Args:
            data_path: æ•°æ®æ ¹ç›®å½•è·¯å¾„
            model_save_path: æ¨¡å‹ä¿å­˜è·¯å¾„
            output_path: è¾“å‡ºè·¯å¾„
            use_gpu: æ˜¯å¦ä½¿ç”¨GPU
            random_state: éšæœºç§å­
            logger: æ—¥å¿—è®°å½•å™¨
        """
        # ä½¿ç”¨é…ç½®æ–‡ä»¶çš„è·¯å¾„æˆ–ç”¨æˆ·æŒ‡å®šè·¯å¾„
        self.data_path = Path(data_path) if data_path else Path(Config.DATA_BASE_PATH)
        self.model_save_path = self.data_path / model_save_path
        self.output_path = self.data_path / output_path
        self.use_gpu = use_gpu
        self.random_state = random_state
        self.logger = logger
        
        # PyTorchè®¾å¤‡
        self.device = DEVICE
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_path.mkdir(parents=True, exist_ok=True)
        self.model_save_path.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨
        self.data_processor = DataProcessor(logger=logger)
        
        # ç¼“å­˜å·²åŠ è½½çš„æ¨¡å‹å’Œç‰¹å¾
        self.loaded_models = {}
        self.loaded_features = {}
        
        self._log(f"é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ (PyTorchç‰ˆæœ¬)")
        self._log(f"æ•°æ®è·¯å¾„: {self.data_path}")
        self._log(f"æ¨¡å‹è·¯å¾„: {self.model_save_path}")
        self._log(f"è¾“å‡ºè·¯å¾„: {self.output_path}")
        self._log(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def _log(self, message: str):
        """è®°å½•æ—¥å¿—"""
        if self.logger:
            self.logger.info(message)
        else:
            print(message)
    
    def _monitor_memory(self, stage: str = ""):
        """ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            memory_info = psutil.Process().memory_info()
            memory_mb = memory_info.rss / 1024 / 1024
            
            # æ·»åŠ GPUå†…å­˜ç›‘æ§
            gpu_memory = ""
            if torch.cuda.is_available():
                gpu_allocated = torch.cuda.memory_allocated() / 1024 / 1024
                gpu_reserved = torch.cuda.memory_reserved() / 1024 / 1024
                gpu_memory = f", GPUå·²åˆ†é…: {gpu_allocated:.1f}MB, GPUå·²ä¿ç•™: {gpu_reserved:.1f}MB"
            
            self._log(f"ğŸ“Š {stage} å†…å­˜ä½¿ç”¨: {memory_mb:.1f}MB{gpu_memory}")
            return memory_mb
        except:
            return 0
    
    def _optimize_memory(self):
        """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        self._monitor_memory("å†…å­˜æ¸…ç†å")
    
    def save_model_and_features(self, model, model_name: str, segment_id: int, 
                               feature_names: List[str], performance: float = None):
        """
        ä¿å­˜æ¨¡å‹å’Œç‰¹å¾ä¿¡æ¯ï¼ˆæ”¯æŒPyTorchæ¨¡å‹ï¼‰
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            model_name: æ¨¡å‹åç§°
            segment_id: æ•°æ®æ®µID
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
            performance: æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
        """
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯PyTorchæ¨¡å‹
            is_pytorch_model = isinstance(model, nn.Module)
            
            if is_pytorch_model:
                # ä¿å­˜PyTorchæ¨¡å‹
                model_path = self.model_save_path / f"{model_name}_segment_{segment_id}.pth"
                
                # ä¿å­˜æ¨¡å‹çŠ¶æ€å­—å…¸å’Œç»“æ„ä¿¡æ¯
                model_info = {
                    'model_name': model_name,
                    'model_class': model.__class__.__name__,
                    'state_dict': model.state_dict(),
                    'model_params': getattr(model, 'params', {}),
                    'input_dim': getattr(model, 'input_dim', None),
                    'device': str(model.device) if hasattr(model, 'device') else str(self.device)
                }
                
                torch.save(model_info, model_path)
                self._log(f"å·²ä¿å­˜PyTorchæ¨¡å‹: {model_path}")
                
                # å¦å¤–ä¿å­˜å®Œæ•´æ¨¡å‹ï¼ˆå¤‡ç”¨ï¼‰
                full_model_path = self.model_save_path / f"{model_name}_segment_{segment_id}_full.pkl"
                try:
                    # å°†æ¨¡å‹ç§»åˆ°CPUå†ä¿å­˜ï¼Œé¿å…è®¾å¤‡ç›¸å…³é—®é¢˜
                    model_cpu = model.cpu()
                    joblib.dump(model_cpu, full_model_path)
                    # æ¢å¤åˆ°åŸè®¾å¤‡
                    model.to(self.device)
                    self._log(f"å·²ä¿å­˜å®Œæ•´PyTorchæ¨¡å‹: {full_model_path}")
                except Exception as e:
                    self._log(f"ä¿å­˜å®Œæ•´PyTorchæ¨¡å‹å¤±è´¥: {str(e)}")
            else:
                # ä¿å­˜éPyTorchæ¨¡å‹ï¼ˆXGBoost, LightGBMç­‰ï¼‰
                model_path = self.model_save_path / f"{model_name}_segment_{segment_id}.pkl"
                joblib.dump(model, model_path)
                self._log(f"å·²ä¿å­˜ä¼ ç»Ÿæ¨¡å‹: {model_path}")
            
            # ä¿å­˜ç‰¹å¾åç§°
            feature_path = self.model_save_path / f"features_segment_{segment_id}.pkl"
            joblib.dump(feature_names, feature_path)
            
            # ä¿å­˜æ¨¡å‹ä¿¡æ¯
            info_path = self.model_save_path / f"info_{model_name}_segment_{segment_id}.json"
            import json
            model_info = {
                'model_name': model_name,
                'segment_id': segment_id,
                'feature_count': len(feature_names),
                'performance': performance,
                'is_pytorch_model': is_pytorch_model,
                'device_used': str(self.device),
                'saved_at': pd.Timestamp.now().isoformat()
            }
            with open(info_path, 'w', encoding='utf-8') as f:
                json.dump(model_info, f, indent=2, ensure_ascii=False)
            
            self._log(f"å·²ä¿å­˜ç‰¹å¾å’Œä¿¡æ¯: {feature_path}, {info_path}")
            
        except Exception as e:
            self._log(f"ä¿å­˜æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
            raise
    
    def load_model_and_features(self, model_name: str, segment_id: int) -> Tuple[Any, List[str]]:
        """
        åŠ è½½æ¨¡å‹å’Œç‰¹å¾ä¿¡æ¯ï¼ˆæ”¯æŒPyTorchæ¨¡å‹ï¼‰
        
        Args:
            model_name: æ¨¡å‹åç§°
            segment_id: æ•°æ®æ®µID
            
        Returns:
            Tuple: (æ¨¡å‹å¯¹è±¡, ç‰¹å¾åç§°åˆ—è¡¨)
        """
        cache_key = f"{model_name}_segment_{segment_id}"
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.loaded_models:
            return self.loaded_models[cache_key], self.loaded_features[cache_key]
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        feature_path = self.model_save_path / f"features_segment_{segment_id}.pkl"
        info_path = self.model_save_path / f"info_{model_name}_segment_{segment_id}.json"
        
        if not feature_path.exists():
            raise FileNotFoundError(f"ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {feature_path}")
        
        try:
            # åŠ è½½ç‰¹å¾åç§°
            feature_names = joblib.load(feature_path)
            
            # è¯»å–æ¨¡å‹ä¿¡æ¯
            is_pytorch_model = False
            if info_path.exists():
                import json
                with open(info_path, 'r', encoding='utf-8') as f:
                    info = json.load(f)
                is_pytorch_model = info.get('is_pytorch_model', False)
            else:
                # é€šè¿‡æ¨¡å‹åç§°åˆ¤æ–­
                is_pytorch_model = model_name in ['NeuralRanker', 'RankNet', 'TransformerRanker']
            
            # åŠ è½½æ¨¡å‹
            if is_pytorch_model:
                model = self._load_pytorch_model(model_name, segment_id)
            else:
                model = self._load_traditional_model(model_name, segment_id)
            
            # ç¼“å­˜åŠ è½½çš„å†…å®¹
            self.loaded_models[cache_key] = model
            self.loaded_features[cache_key] = feature_names
            
            self._log(f"å·²åŠ è½½æ¨¡å‹: {model_name}_segment_{segment_id}")
            return model, feature_names
            
        except Exception as e:
            self._log(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
            raise
    
    def _load_pytorch_model(self, model_name: str, segment_id: int):
        """åŠ è½½PyTorchæ¨¡å‹"""
        # ä¼˜å…ˆå°è¯•åŠ è½½.pthæ–‡ä»¶
        pth_path = self.model_save_path / f"{model_name}_segment_{segment_id}.pth"
        full_pkl_path = self.model_save_path / f"{model_name}_segment_{segment_id}_full.pkl"
        
        if pth_path.exists():
            try:
                # åŠ è½½æ¨¡å‹ä¿¡æ¯
                model_info = torch.load(pth_path, map_location=self.device)
                
                # é‡æ–°åˆ›å»ºæ¨¡å‹
                input_dim = model_info.get('input_dim')
                model_params = model_info.get('model_params', {})
                
                if input_dim is None:
                    raise ValueError(f"æ— æ³•è·å–æ¨¡å‹è¾“å…¥ç»´åº¦")
                
                # åˆ›å»ºæ–°çš„æ¨¡å‹å®ä¾‹
                model = ModelFactory.create_model(
                    model_name,
                    use_gpu=self.use_gpu,
                    input_dim=input_dim,
                    **model_params
                )
                
                # åŠ è½½çŠ¶æ€å­—å…¸
                model.load_state_dict(model_info['state_dict'])
                model.eval()  # è®¾ä¸ºè¯„ä¼°æ¨¡å¼
                
                self._log(f"å·²ä».pthæ–‡ä»¶åŠ è½½PyTorchæ¨¡å‹: {pth_path}")
                return model
                
            except Exception as e:
                self._log(f"ä».pthæ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•")
        
        # å¤‡ç”¨æ–¹æ³•ï¼šåŠ è½½å®Œæ•´æ¨¡å‹
        if full_pkl_path.exists():
            try:
                model = joblib.load(full_pkl_path)
                model.to(self.device)
                model.eval()
                self._log(f"å·²ä»å®Œæ•´æ¨¡å‹æ–‡ä»¶åŠ è½½: {full_pkl_path}")
                return model
            except Exception as e:
                self._log(f"ä»å®Œæ•´æ¨¡å‹æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
        
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°PyTorchæ¨¡å‹æ–‡ä»¶: {model_name}_segment_{segment_id}")
    
    def _load_traditional_model(self, model_name: str, segment_id: int):
        """åŠ è½½ä¼ ç»Ÿæ¨¡å‹ï¼ˆXGBoost, LightGBMç­‰ï¼‰"""
        model_path = self.model_save_path / f"{model_name}_segment_{segment_id}.pkl"
        
        if not model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        
        model = joblib.load(model_path)
        self._log(f"å·²åŠ è½½ä¼ ç»Ÿæ¨¡å‹: {model_path}")
        return model
    
    def predict_segment(self, segment_id: int, model_name: str = 'XGBRanker') -> Optional[pd.DataFrame]:
        """
        é¢„æµ‹å•ä¸ªæ•°æ®æ®µï¼ˆPyTorchç‰ˆæœ¬ï¼‰
        
        Args:
            segment_id: æ•°æ®æ®µID
            model_name: æ¨¡å‹åç§°
            
        Returns:
            Optional[pd.DataFrame]: é¢„æµ‹ç»“æœ
        """
        self._log(f"å¼€å§‹é¢„æµ‹ segment_{segment_id}")
        self._monitor_memory("é¢„æµ‹å¼€å§‹å‰")
        
        try:
            # åŠ è½½æ¨¡å‹å’Œç‰¹å¾
            self._log(f"æ­£åœ¨åŠ è½½æ¨¡å‹å’Œç‰¹å¾...")
            model, feature_names = self.load_model_and_features(model_name, segment_id)
            self._monitor_memory("æ¨¡å‹åŠ è½½å")
            
            # æŸ¥æ‰¾æµ‹è¯•æ•°æ®æ–‡ä»¶
            self._log(f"æ­£åœ¨æŸ¥æ‰¾æµ‹è¯•æ•°æ®æ–‡ä»¶...")
            possible_test_files = [
                self.data_path / "segmented" / "test" / f"test_segment_{segment_id}.parquet",
                self.data_path / "encode" / "test" / f"test_segment_{segment_id}_encoded.parquet",
                self.data_path / "test" / f"test_segment_{segment_id}.parquet"
            ]
            
            test_file = None
            for file_path in possible_test_files:
                if file_path.exists():
                    test_file = file_path
                    break
            
            if test_file is None:
                raise FileNotFoundError(f"æ‰¾ä¸åˆ° segment_{segment_id} çš„æµ‹è¯•æ–‡ä»¶")
            
            # åŠ è½½æµ‹è¯•æ•°æ®
            self._log(f"æ­£åœ¨åŠ è½½æµ‹è¯•æ•°æ®: {test_file}")
            test_df = pd.read_parquet(test_file)
            self._log(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_df.shape}")
            self._monitor_memory("æµ‹è¯•æ•°æ®åŠ è½½å")
            
            # æ‰§è¡Œç®€åŒ–çš„é¢„æµ‹æµç¨‹
            return self._predict_segment_simplified(test_df, model, feature_names, segment_id)
                
        except Exception as e:
            self._log(f"é¢„æµ‹ segment_{segment_id} å¤±è´¥: {str(e)}")
            return None
        finally:
            # æ¸…ç†å†…å­˜
            self._optimize_memory()
    
    def _predict_segment_simplified(self, test_df: pd.DataFrame, model, 
                                  feature_names: List[str], segment_id: int) -> pd.DataFrame:
        """ç®€åŒ–ç‰ˆé¢„æµ‹æµç¨‹ï¼ˆPyTorchç‰ˆæœ¬ï¼‰"""
        self._log(f"ğŸš€ æ‰§è¡Œç®€åŒ–ç‰ˆé¢„æµ‹æµç¨‹...")
        
        # å‡†å¤‡ç‰¹å¾æ•°æ®
        self._log(f"å‡†å¤‡ç‰¹å¾æ•°æ®...")
        X_test = self._prepare_test_features_simplified(test_df, feature_names)
        self._monitor_memory("ç‰¹å¾å‡†å¤‡å")
        
        # æ‰§è¡Œé¢„æµ‹
        self._log(f"æ‰§è¡Œæ¨¡å‹é¢„æµ‹...")
        if isinstance(model, nn.Module):
            # PyTorchæ¨¡å‹é¢„æµ‹
            pred_scores = self._predict_pytorch_model(model, X_test)
        else:
            # ä¼ ç»Ÿæ¨¡å‹é¢„æµ‹
            pred_scores = model.predict(X_test)
        
        self._monitor_memory("æ¨¡å‹é¢„æµ‹å")
        
        # åˆ›å»ºç»“æœDataFrame
        self._log(f"åˆ›å»ºé¢„æµ‹ç»“æœ...")
        results = test_df[['Id', 'ranker_id']].copy()
        results['prediction_score'] = pred_scores
        
        # ä½¿ç”¨ç®€åŒ–çš„æ’ååˆ†é…æ–¹æ³•
        self._log(f"åˆ†é…å”¯ä¸€æ’å...")
        results = self._assign_unique_rankings(results)
        
        self._log(f"âœ… ç®€åŒ–é¢„æµ‹å®Œæˆï¼Œç»“æœå½¢çŠ¶: {results.shape}")
        
        # å¿«é€ŸéªŒè¯ï¼ˆä»…æŠ½æ ·ï¼‰
        self._quick_validation(results)
        
        return results[['Id', 'ranker_id', 'selected']]
    
    def _predict_pytorch_model(self, model: nn.Module, X_test: np.ndarray) -> np.ndarray:
        """
        ä½¿ç”¨PyTorchæ¨¡å‹è¿›è¡Œé¢„æµ‹
        
        Args:
            model: PyTorchæ¨¡å‹
            X_test: æµ‹è¯•ç‰¹å¾
            
        Returns:
            np.ndarray: é¢„æµ‹åˆ†æ•°
        """
        model.eval()
        predictions = []
        
        # æ‰¹é‡é¢„æµ‹ä»¥é¿å…å†…å­˜é—®é¢˜
        batch_size = 1000
        
        with torch.no_grad():
            for i in range(0, len(X_test), batch_size):
                batch = X_test[i:i+batch_size]
                batch_tensor = torch.FloatTensor(batch).to(self.device)
                
                # é¢„æµ‹
                batch_pred = model(batch_tensor)
                
                # è½¬æ¢ä¸ºnumpy
                if isinstance(batch_pred, torch.Tensor):
                    batch_pred = batch_pred.cpu().numpy().flatten()
                
                predictions.append(batch_pred)
        
        return np.concatenate(predictions)
    
    def _prepare_test_features_simplified(self, test_df: pd.DataFrame, 
                                        feature_names: List[str]) -> np.ndarray:
        """
        ç®€åŒ–ç‰ˆç‰¹å¾å‡†å¤‡
        
        Args:
            test_df: æµ‹è¯•æ•°æ®
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
            
        Returns:
            np.ndarray: ç‰¹å¾çŸ©é˜µ
        """
        # ç¡®ä¿æµ‹è¯•æ•°æ®åŒ…å«æ‰€éœ€ç‰¹å¾
        missing_features = set(feature_names) - set(test_df.columns)
        if missing_features:
            self._log(f"è­¦å‘Š: æµ‹è¯•æ•°æ®ç¼ºå°‘ç‰¹å¾: {missing_features}")
            # ä¸ºç¼ºå¤±ç‰¹å¾æ·»åŠ 0å€¼
            for feature in missing_features:
                test_df[feature] = 0.0
        
        # å¤„ç†ç¼ºå¤±å€¼
        test_df[feature_names] = test_df[feature_names].fillna(
            test_df[feature_names].median()
        )
        
        return test_df[feature_names].values.astype(np.float32)
    
    def _assign_unique_rankings(self, results: pd.DataFrame) -> pd.DataFrame:
        """
        ä½¿ç”¨ç®€åŒ–æ–¹æ³•åˆ†é…å”¯ä¸€æ’å
        
        Args:
            results: åŒ…å«Id, ranker_id, prediction_scoreçš„DataFrame
            
        Returns:
            pd.DataFrame: æ·»åŠ äº†selectedåˆ—çš„DataFrame
        """
        self._log("ğŸ¯ ä½¿ç”¨ç®€åŒ–æ–¹æ³•åˆ†é…å”¯ä¸€æ’å...")
        
        # ç¡®ä¿å”¯ä¸€æ’åï¼šä½¿ç”¨Idä½œä¸ºtie-breaker
        results = results.sort_values(['ranker_id', 'prediction_score', 'Id'], 
                                    ascending=[True, False, True])
        results['selected'] = results.groupby('ranker_id').cumcount() + 1
        
        self._log("âœ… æ’ååˆ†é…å®Œæˆ")
        return results
    
    def _quick_validation(self, results: pd.DataFrame, sample_size: int = 10):
        """
        å¿«é€ŸéªŒè¯æ’åçš„æœ‰æ•ˆæ€§
        
        Args:
            results: é¢„æµ‹ç»“æœ
            sample_size: éªŒè¯æ ·æœ¬æ•°é‡
        """
        self._log("ğŸ” æ‰§è¡Œå¿«é€ŸéªŒè¯...")
        
        unique_rankers = results['ranker_id'].unique()
        sample_rankers = np.random.choice(
            unique_rankers, 
            min(sample_size, len(unique_rankers)), 
            replace=False
        )
        
        all_valid = True
        for ranker_id in sample_rankers:
            group_data = results[results['ranker_id'] == ranker_id]
            ranks = sorted(group_data['selected'].values)
            expected_ranks = list(range(1, len(group_data) + 1))
            
            if ranks != expected_ranks:
                self._log(f"âŒ ranker_id {ranker_id} æ’åæ— æ•ˆ: {ranks[:5]}...")
                all_valid = False
                break
        
        if all_valid:
            self._log(f"âœ… æŠ½æ ·éªŒè¯é€šè¿‡ ({sample_size}ä¸ªç»„)")
        else:
            self._log(f"âš ï¸ æŠ½æ ·éªŒè¯å‘ç°é—®é¢˜ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
    
    def predict_all(self, 
                   segments: List[int] = None, 
                   model_names: List[str] = None,
                   ensemble_method: str = 'average') -> Optional[pd.DataFrame]:
        """
        é¢„æµ‹æ‰€æœ‰æŒ‡å®šæ•°æ®æ®µå¹¶ç”Ÿæˆæœ€ç»ˆæäº¤æ–‡ä»¶ï¼ˆPyTorchç‰ˆæœ¬ï¼‰
        
        Args:
            segments: è¦é¢„æµ‹çš„æ•°æ®æ®µåˆ—è¡¨
            model_names: è¦ä½¿ç”¨çš„æ¨¡å‹åç§°åˆ—è¡¨
            ensemble_method: é›†æˆæ–¹æ³•
            
        Returns:
            Optional[pd.DataFrame]: æœ€ç»ˆé¢„æµ‹ç»“æœ
        """
        if segments is None:
            segments = [0, 1, 2]  # é»˜è®¤é¢„æµ‹å‰3ä¸ªæ®µ
        if model_names is None:
            model_names = ['XGBRanker']  # é»˜è®¤ä½¿ç”¨XGBRanker
        
        self._log(f"å¼€å§‹é¢„æµ‹æ‰€æœ‰æ•°æ®æ®µ: {segments}")
        self._log(f"ä½¿ç”¨æ¨¡å‹: {model_names}")
        self._monitor_memory("é¢„æµ‹å¼€å§‹å‰")
        
        all_predictions = []
        
        # å¯¹æ¯ä¸ªæ•°æ®æ®µè¿›è¡Œé¢„æµ‹
        for segment_id in progress_bar(segments, desc="é¢„æµ‹æ•°æ®æ®µ"):
            self._log(f"\n{'='*50}")
            segment_predictions = {}
            
            # ä½¿ç”¨æ¯ä¸ªæ¨¡å‹è¿›è¡Œé¢„æµ‹
            for model_name in model_names:
                try:
                    self._log(f"ğŸ”„ ä½¿ç”¨{model_name}é¢„æµ‹segment_{segment_id}...")
                    prediction = self.predict_segment(segment_id, model_name)
                    if prediction is not None:
                        segment_predictions[model_name] = prediction
                        
                        # ä¿å­˜å•ä¸ªæ®µå•ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ
                        segment_output = self.output_path / f"{model_name}_segment_{segment_id}_prediction.csv"
                        prediction.to_csv(segment_output, index=False)
                        self._log(f"å·²ä¿å­˜é¢„æµ‹ç»“æœ: {segment_output}")
                    
                except Exception as e:
                    self._log(f"æ¨¡å‹ {model_name} é¢„æµ‹ segment_{segment_id} å¤±è´¥: {e}")
                    continue
                finally:
                    # æ¸…ç†GPUå†…å­˜
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
            
            # å¦‚æœæœ‰å¤šä¸ªæ¨¡å‹ï¼Œè¿›è¡Œç®€åŒ–é›†æˆ
            if len(segment_predictions) > 1:
                ensemble_prediction = self._ensemble_predictions_simplified(
                    segment_predictions, ensemble_method
                )
                all_predictions.append(ensemble_prediction)
            elif len(segment_predictions) == 1:
                all_predictions.append(list(segment_predictions.values())[0])
            else:
                self._log(f"segment_{segment_id} æ²¡æœ‰æˆåŠŸçš„é¢„æµ‹ç»“æœ")
                continue
            
            # æ¸…ç†å½“å‰æ®µçš„å†…å­˜
            self._optimize_memory()
        
        # åˆå¹¶æ‰€æœ‰é¢„æµ‹ç»“æœ
        if not all_predictions:
            self._log("æ²¡æœ‰æˆåŠŸçš„é¢„æµ‹ç»“æœ")
            return None
        
        self._log(f"ğŸ”— åˆå¹¶æ‰€æœ‰é¢„æµ‹ç»“æœ...")
        self._monitor_memory("åˆå¹¶å‰")
        
        final_submission = pd.concat(all_predictions, ignore_index=True)
        
        # æ¸…ç†ä¸­é—´ç»“æœ
        del all_predictions
        self._optimize_memory()
        
        # æŒ‰Idæ’åº
        final_submission = final_submission.sort_values('Id').reset_index(drop=True)
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        model_suffix = "_".join(model_names) if len(model_names) > 1 else model_names[0]
        final_output = self.output_path / f"{model_suffix}_final_submission.csv"
        final_submission.to_csv(final_output, index=False)
        
        # ç»“æœæ€»ç»“
        self._log(f"\n{'='*50}")
        self._log(f"é¢„æµ‹å®Œæˆ!")
        self._log(f"æœ€ç»ˆæäº¤æ–‡ä»¶: {final_output}")
        self._log(f"æ€»è®°å½•æ•°: {len(final_submission)}")
        self._log(f"å”¯ä¸€ranker_idæ•°é‡: {final_submission['ranker_id'].nunique()}")
        
        self._monitor_memory("æœ€ç»ˆå®Œæˆ")
        return final_submission
    
    def _ensemble_predictions_simplified(self, 
                                       predictions: Dict[str, pd.DataFrame],
                                       method: str = 'average') -> pd.DataFrame:
        """
        ç®€åŒ–ç‰ˆé›†æˆå¤šä¸ªæ¨¡å‹é¢„æµ‹
        
        Args:
            predictions: æ¨¡å‹é¢„æµ‹ç»“æœå­—å…¸
            method: é›†æˆæ–¹æ³•
            
        Returns:
            pd.DataFrame: é›†æˆåçš„é¢„æµ‹ç»“æœ
        """
        self._log(f"é›†æˆ {len(predictions)} ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœï¼Œæ–¹æ³•: {method}")
        
        if len(predictions) == 1:
            return list(predictions.values())[0]
        
        # è·å–åŸºç¡€æ•°æ®æ¡†æ¶
        base_df = list(predictions.values())[0][['Id', 'ranker_id']].copy()
        
        # ç®€åŒ–çš„å¹³å‡é›†æˆ
        all_scores = []
        for model_name, pred_df in predictions.items():
            # åˆå¹¶è·å–åˆ†æ•°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            temp_df = base_df.merge(pred_df, on=['Id', 'ranker_id'], how='left')
            if 'prediction_score' in temp_df.columns:
                all_scores.append(temp_df['prediction_score'].values)
            else:
                # å¦‚æœæ²¡æœ‰åˆ†æ•°ï¼Œç”¨æ’åçš„å€’æ•°ä½œä¸ºåˆ†æ•°
                max_rank = temp_df.groupby('ranker_id')['selected'].transform('max')
                scores = max_rank - temp_df['selected'] + 1
                all_scores.append(scores.values)
        
        # è®¡ç®—å¹³å‡åˆ†æ•°
        if all_scores:
            avg_scores = np.mean(all_scores, axis=0)
            base_df['prediction_score'] = avg_scores
            
            # é‡æ–°åˆ†é…æ’å
            base_df = self._assign_unique_rankings(base_df)
        else:
            # å¦‚æœæ²¡æœ‰åˆ†æ•°ä¿¡æ¯ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹çš„ç»“æœ
            first_result = list(predictions.values())[0]
            base_df = base_df.merge(first_result[['Id', 'ranker_id', 'selected']], 
                                  on=['Id', 'ranker_id'], how='left')
        
        return base_df[['Id', 'ranker_id', 'selected']]
    
    def validate_predictions(self, submission: pd.DataFrame, sample_size: int = 5):
        """
        éªŒè¯é¢„æµ‹ç»“æœçš„æœ‰æ•ˆæ€§
        
        Args:
            submission: æäº¤ç»“æœ
            sample_size: æŠ½æ ·éªŒè¯çš„æ•°é‡
        """
        self._log("\néªŒè¯é¢„æµ‹ç»“æœ:")
        
        unique_rankers = submission['ranker_id'].unique()
        total_groups = len(unique_rankers)
        valid_groups = 0
        
        # æ£€æŸ¥æ‰€æœ‰ç»„
        for ranker_id in unique_rankers:
            group_data = submission[submission['ranker_id'] == ranker_id]
            ranks = sorted(group_data['selected'].values)
            expected_ranks = list(range(1, len(group_data) + 1))
            if ranks == expected_ranks:
                valid_groups += 1
        
        self._log(f"æ€»ç»„æ•°: {total_groups}")
        self._log(f"æœ‰æ•ˆç»„æ•°: {valid_groups}")
        self._log(f"æœ‰æ•ˆç‡: {valid_groups/total_groups:.2%}")
        
        # éšæœºæŠ½æ ·è¯¦ç»†æ£€æŸ¥
        if sample_size > 0:
            sample_rankers = np.random.choice(
                unique_rankers, 
                min(sample_size, len(unique_rankers)), 
                replace=False
            )
            
            self._log(f"\næŠ½æ ·æ£€æŸ¥ {len(sample_rankers)} ä¸ªç»„:")
            for ranker_id in sample_rankers:
                group_data = submission[submission['ranker_id'] == ranker_id]
                ranks = sorted(group_data['selected'].values)
                expected_ranks = list(range(1, len(group_data) + 1))
                is_valid = ranks == expected_ranks
                self._log(f"  ranker_id {ranker_id}: æ’å{'æœ‰æ•ˆ' if is_valid else 'æ— æ•ˆ'} "
                         f"(å¤§å°: {len(group_data)})")
                if not is_valid:
                    self._log(f"    å®é™…æ’å: {ranks[:10]}...")
                    self._log(f"    æœŸæœ›æ’å: {expected_ranks[:10]}...")
    
    def get_available_models(self) -> Dict[str, List[int]]:
        """
        è·å–å¯ç”¨çš„æ¨¡å‹å’Œå¯¹åº”çš„æ•°æ®æ®µ
        
        Returns:
            Dict: {æ¨¡å‹åç§°: [å¯ç”¨çš„æ®µIDåˆ—è¡¨]}
        """
        available_models = {}
        
        if not self.model_save_path.exists():
            return available_models
        
        # æ‰«ææ¨¡å‹æ–‡ä»¶ï¼ˆæ”¯æŒ.pklå’Œ.pthæ–‡ä»¶ï¼‰
        for model_file in self.model_save_path.glob("*"):
            if model_file.name.startswith("features_") or model_file.name.startswith("info_"):
                continue
            
            # è§£ææ–‡ä»¶å
            if model_file.suffix in ['.pkl', '.pth']:
                name_parts = model_file.stem.split("_")
                
                # å¤„ç†_full.pklåç¼€
                if name_parts[-1] == "full":
                    name_parts = name_parts[:-1]
                
                if len(name_parts) >= 3 and name_parts[-2] == "segment":
                    model_name = "_".join(name_parts[:-2])
                    try:
                        segment_id = int(name_parts[-1])
                        if model_name not in available_models:
                            available_models[model_name] = []
                        if segment_id not in available_models[model_name]:
                            available_models[model_name].append(segment_id)
                    except ValueError:
                        continue
        
        # æ’åºæ®µID
        for model_name in available_models:
            available_models[model_name].sort()
        
        return available_models
    
    def print_model_summary(self):
        """æ‰“å°æ¨¡å‹æ‘˜è¦ä¿¡æ¯"""
        available_models = self.get_available_models()
        
        if not available_models:
            self._log("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹")
            return
        
        self._log("\nå¯ç”¨æ¨¡å‹æ‘˜è¦ (PyTorchç‰ˆæœ¬):")
        self._log("="*50)
        
        for model_name, segments in available_models.items():
            is_pytorch = model_name in ['NeuralRanker', 'RankNet', 'TransformerRanker']
            model_type = "PyTorch" if is_pytorch else "ä¼ ç»Ÿ"
            self._log(f"{model_name} ({model_type}): æ®µ {segments}")
            
            # å°è¯•è¯»å–æ¨¡å‹ä¿¡æ¯
            for segment_id in segments[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªæ®µçš„è¯¦ç»†ä¿¡æ¯
                info_path = self.model_save_path / f"info_{model_name}_segment_{segment_id}.json"
                if info_path.exists():
                    try:
                        import json
                        with open(info_path, 'r', encoding='utf-8') as f:
                            info = json.load(f)
                        performance = info.get('performance', 'N/A')
                        if isinstance(performance, (int, float)):
                            performance = f"{performance:.4f}"
                        self._log(f"  æ®µ{segment_id}: ç‰¹å¾æ•°={info.get('feature_count', 'N/A')}, "
                                 f"æ€§èƒ½={performance}, è®¾å¤‡={info.get('device_used', 'N/A')}")
                    except:
                        pass