"""
ä¸»ç¨‹åºå…¥å£ - é‡æ„ç‰ˆ

ä¸“æ³¨äºï¼š
- ç”¨æˆ·äº¤äº’
- ç¨‹åºæµç¨‹æ§åˆ¶
- é”™è¯¯å¤„ç†
- ç»“æœå±•ç¤º

ä½œè€…: Flight Ranking Team
ç‰ˆæœ¬: 4.0 (é‡æ„ç‰ˆ)
"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Any
import torch

# å¯¼å…¥æ¨¡å—
from config import Config
from analyzer import FlightRankingAnalyzer
from predictor import FlightRankingPredictor


class UserInterface:
    """ç”¨æˆ·äº¤äº’ç•Œé¢"""
    #@staticmethodç”¨äºå®šä¹‰é™æ€æ–¹æ³•ï¼Œä¸éœ€è¦å®ä¾‹åŒ–ç±»å³å¯è°ƒç”¨ï¼Œ
    #å®ƒç±»ä¼¼äºæ™®é€šå‡½æ•°ï¼Œä½†è¢«å°è£…åœ¨ç±»çš„å‘½åç©ºé—´ä¸­ï¼Œä¸»è¦ç”¨äºé€»è¾‘ä¸Šçš„ç»„ç»‡ã€‚
    @staticmethod
    def get_run_mode() -> str:
        """è·å–è¿è¡Œæ¨¡å¼"""
        print("\n" + "="*60)
        print("èˆªç­æ’åºåˆ†æç³»ç»Ÿ v4.0 (é‡æ„ç‰ˆ)")
        print("="*60)
        
        print("\nè¿è¡Œæ¨¡å¼:")
        print("1. å®Œæ•´æµç¨‹ (è®­ç»ƒ + é¢„æµ‹)")
        print("2. ä»…è®­ç»ƒæ¨¡å‹")
        print("3. ä»…é¢„æµ‹ (ä½¿ç”¨å·²ä¿å­˜çš„æ¨¡å‹)")
        
        while True:
            choice = input("\nè¯·é€‰æ‹©è¿è¡Œæ¨¡å¼ (1-3): ").strip()
            if choice in ['1', '2', '3']:
                return choice
            print("è¯·è¾“å…¥æœ‰æ•ˆé€‰æ‹© (1-3)")
    #è·å¾—äº†è®­ç»ƒé…ç½®ï¼ŒåŒ…æ‹¬ä½¿ç”¨çš„æ•°æ®æ¨¡å¼ã€æ¨¡å‹é€‰æ‹©ã€è‡ªåŠ¨è°ƒå‚ç­‰é€‰é¡¹ã€‚
    @staticmethod
    def get_training_config() -> Dict[str, Any]:
        """è·å–è®­ç»ƒé…ç½®"""
        config = {}
        
        # æ•°æ®æ¨¡å¼
        print("\næ•°æ®åŠ è½½æ¨¡å¼:")
        print("1. æŠ½æ ·æ¨¡å¼ (æ¨è)")
        print("2. å…¨é‡æ¨¡å¼")
        
        data_mode = input("è¯·é€‰æ‹© (1-2): ").strip()
        config['use_sampling'] = data_mode == '1'
        
        if config['use_sampling']:
            try:
                config['num_groups'] = int(input(f"æŠ½æ ·ç»„æ•° (é»˜è®¤{Config.DEFAULT_NUM_GROUPS}): ") or Config.DEFAULT_NUM_GROUPS)
                config['min_group_size'] = int(input(f"æœ€å°ç»„å¤§å° (é»˜è®¤{Config.DEFAULT_MIN_GROUP_SIZE}): ") or Config.DEFAULT_MIN_GROUP_SIZE)
            except ValueError:
                config['num_groups'] = Config.DEFAULT_NUM_GROUPS
                config['min_group_size'] = Config.DEFAULT_MIN_GROUP_SIZE
        
        # æ¨¡å‹é€‰æ‹©
        print("\nå¯ç”¨æ¨¡å‹:")
        for i, model in enumerate(Config.AVAILABLE_MODELS, 1):
            model_type = "ğŸ”¥ PyTorch" if Config.is_pytorch_model(model) else "ğŸ“Š ä¼ ç»Ÿ"
            print(f"{i}. {model} ({model_type})")
        print(f"{len(Config.AVAILABLE_MODELS) + 1}. æ‰€æœ‰æ¨¡å‹")
        
        model_input = input("\né€‰æ‹©æ¨¡å‹ (ç”¨é€—å·åˆ†éš”): ").strip()
        if model_input:
            try:
                choices = [int(x.strip()) for x in model_input.split(',')]
                if len(Config.AVAILABLE_MODELS) + 1 in choices:
                    config['selected_models'] = Config.AVAILABLE_MODELS
                else:
                    config['selected_models'] = [
                        Config.AVAILABLE_MODELS[i-1] 
                        for i in choices 
                        if 1 <= i <= len(Config.AVAILABLE_MODELS)
                    ]
            except:
                config['selected_models'] = ['XGBRanker', 'NeuralRanker']
        else:
            config['selected_models'] = ['XGBRanker', 'NeuralRanker']
        
        # è‡ªåŠ¨è°ƒå‚
        config['enable_auto_tuning'] = input("\nå¯ç”¨è‡ªåŠ¨è°ƒå‚? (y/n): ").strip().lower() == 'y'
        if config['enable_auto_tuning']:
            try:
                config['auto_tuning_trials'] = int(input("è°ƒå‚è¯•éªŒæ¬¡æ•° (é»˜è®¤50): ") or 50)
            except:
                config['auto_tuning_trials'] = 50
        
        # æ¨¡å‹ä¿å­˜
        config['save_models'] = input("ä¿å­˜è®­ç»ƒçš„æ¨¡å‹? (y/n): ").strip().lower() != 'n'
        
        return config
    
    @staticmethod
    def get_prediction_config() -> Dict[str, Any]:
        """è·å–é¢„æµ‹é…ç½®"""
        config = {}
        
        # åˆå§‹åŒ–é¢„æµ‹å™¨æ£€æŸ¥å¯ç”¨æ¨¡å‹
        predictor = FlightRankingPredictor(Config.DATA_BASE_PATH)
        available_models = predictor.get_available_models()
        
        if not available_models:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä¿å­˜çš„æ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
            config['prediction_possible'] = False
            return config
        
        print("\nå¯ç”¨çš„å·²ä¿å­˜æ¨¡å‹:")
        for model_name, segments in available_models.items():
            model_type = "ğŸ”¥ PyTorch" if Config.is_pytorch_model(model_name) else "ğŸ“Š ä¼ ç»Ÿ"
            print(f"  {model_name} ({model_type}): æ®µ {segments}")
        
        # é€‰æ‹©æ¨¡å‹
        model_names = list(available_models.keys())
        print(f"\næ¨¡å‹é€‰æ‹©:")
        for i, model_name in enumerate(model_names, 1):
            print(f"{i}. {model_name}")
        print(f"{len(model_names) + 1}. æ‰€æœ‰æ¨¡å‹")
        
        model_input = input("é€‰æ‹©æ¨¡å‹ (ç”¨é€—å·åˆ†éš”): ").strip()
        if model_input:
            try:
                choices = [int(x.strip()) for x in model_input.split(',')]
                if len(model_names) + 1 in choices:
                    config['prediction_models'] = model_names
                else:
                    config['prediction_models'] = [
                        model_names[i-1] for i in choices if 1 <= i <= len(model_names)
                    ]
            except:
                config['prediction_models'] = model_names
        else:
            config['prediction_models'] = model_names
        
        # é€‰æ‹©æ•°æ®æ®µ
        all_segments = set()
        for segments in available_models.values():
            all_segments.update(segments)
        all_segments = sorted(list(all_segments))
        
        print(f"\nå¯é¢„æµ‹æ•°æ®æ®µ: {all_segments}")
        segment_input = input("é€‰æ‹©æ•°æ®æ®µ (ç”¨é€—å·åˆ†éš”ï¼Œé»˜è®¤å…¨éƒ¨): ").strip()
        
        if segment_input:
            try:
                config['prediction_segments'] = [int(s.strip()) for s in segment_input.split(',')]
                config['prediction_segments'] = [s for s in config['prediction_segments'] if s in all_segments]
            except:
                config['prediction_segments'] = all_segments
        else:
            config['prediction_segments'] = all_segments
        
        # é›†æˆæ–¹æ³•
        print("\né›†æˆæ–¹æ³•:")
        print("1. å¹³å‡åˆ†æ•° (average)")
        print("2. æ’åæŠ•ç¥¨ (voting)")
        
        ensemble_choice = input("é€‰æ‹©é›†æˆæ–¹æ³• (1-2): ").strip()
        config['ensemble_method'] = 'voting' if ensemble_choice == '2' else 'average'
        
        config['prediction_possible'] = True
        return config


class SystemChecker:
    """ç³»ç»Ÿæ£€æŸ¥å™¨"""
    
    @staticmethod
    def check_gpu() -> bool:
        """æ£€æŸ¥GPUå¯ç”¨æ€§"""
        if torch.cuda.is_available():
            device_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"âœ“ GPUå¯ç”¨: {device_name} ({gpu_memory:.1f}GB)")
            return True
        else:
            print("âš ï¸ GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
            return False
    
    @staticmethod
    def validate_data_files() -> tuple[List[Path], List[Path]]:
        """éªŒè¯æ•°æ®æ–‡ä»¶"""
        train_files = []
        test_files = []
        
        # æŸ¥æ‰¾è®­ç»ƒæ–‡ä»¶
        train_dir = Config.TRAIN_DATA_PATH
        if train_dir.exists():
            train_files = sorted(train_dir.glob("*.parquet"))
        
        # æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶
        test_dir = Config.TEST_DATA_PATH
        if test_dir.exists():
            test_files = sorted(test_dir.glob("*.parquet"))
        
        print(f"\næ•°æ®æ–‡ä»¶æ£€æŸ¥:")
        print(f"è®­ç»ƒæ–‡ä»¶: {len(train_files)} ä¸ª")
        print(f"æµ‹è¯•æ–‡ä»¶: {len(test_files)} ä¸ª")
        
        if not train_files:
            raise FileNotFoundError("æœªæ‰¾åˆ°è®­ç»ƒæ–‡ä»¶")
        
        return train_files, test_files


class WorkflowManager:
    """å·¥ä½œæµç®¡ç†å™¨"""
    
    def __init__(self):
        self.ui = UserInterface()
        self.checker = SystemChecker()
    
    def run(self):
        """è¿è¡Œä¸»å·¥ä½œæµ"""
        try:
            # ç³»ç»Ÿæ£€æŸ¥
            print("ğŸ” ç³»ç»Ÿæ£€æŸ¥...")
            use_gpu = self.checker.check_gpu()
            train_files, test_files = self.checker.validate_data_files()
            
            # è·å–ç”¨æˆ·é…ç½®
            run_mode = self.ui.get_run_mode()
            
            if run_mode == '3':
                # ä»…é¢„æµ‹æ¨¡å¼
                self._run_prediction_only()
            else:
                # è®­ç»ƒæ¨¡å¼
                self._run_training_workflow(run_mode, use_gpu, train_files, test_files)
            
            print("\nğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆ!")
            
        except KeyboardInterrupt:
            print("\nâš ï¸ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        finally:
            input("\næŒ‰Enteré”®é€€å‡º...")
    
    def _run_prediction_only(self):
        """ä»…é¢„æµ‹æ¨¡å¼"""
        print("\nğŸ“Š ä»…é¢„æµ‹æ¨¡å¼")
        
        config = self.ui.get_prediction_config()
        if not config.get('prediction_possible', False):
            return
        
        # åˆå§‹åŒ–é¢„æµ‹å™¨
        predictor = FlightRankingPredictor(Config.DATA_BASE_PATH)
        
        # æ‰§è¡Œé¢„æµ‹
        result = predictor.predict_all(
            segments=config['prediction_segments'],
            model_names=config['prediction_models'],
            ensemble_method=config['ensemble_method']
        )
        
        if result is not None:
            print(f"âœ… é¢„æµ‹å®Œæˆï¼Œç»“æœè®°å½•æ•°: {len(result)}")
        else:
            print("âŒ é¢„æµ‹å¤±è´¥")
    
    def _run_training_workflow(self, run_mode: str, use_gpu: bool, 
                              train_files: List[Path], test_files: List[Path]):
        """è®­ç»ƒå·¥ä½œæµ"""
        print(f"\nğŸš€ è®­ç»ƒæ¨¡å¼ ({'å®Œæ•´æµç¨‹' if run_mode == '1' else 'ä»…è®­ç»ƒ'})")
        
        config = self.ui.get_training_config()
        
        # æ˜¾ç¤ºé…ç½®æ€»ç»“
        print(f"\né…ç½®æ€»ç»“:")
        print(f"  GPU: {'å¯ç”¨' if use_gpu else 'å…³é—­'}")
        print(f"  æ•°æ®æ¨¡å¼: {'æŠ½æ ·' if config['use_sampling'] else 'å…¨é‡'}")
        print(f"  æ¨¡å‹: {', '.join(config['selected_models'])}")
        print(f"  è‡ªåŠ¨è°ƒå‚: {'å¯ç”¨' if config['enable_auto_tuning'] else 'å…³é—­'}")
        
        input("\næŒ‰Enteré”®å¼€å§‹...")
        
        # åˆå§‹åŒ–åˆ†æå™¨
        analyzer = FlightRankingAnalyzer(
            use_gpu=use_gpu,
            selected_models=config['selected_models'],
            enable_auto_tuning=config['enable_auto_tuning'],
            auto_tuning_trials=config.get('auto_tuning_trials', 50),
            save_models=config['save_models']
        )
        
        # è®­ç»ƒé˜¶æ®µ
        train_results = {}
        for i, train_file in enumerate(train_files):
            print(f"\n{'='*50}")
            print(f"è®­ç»ƒæ®µ {i}: {train_file.name}")
            print('='*50)
            
            try:
                result = analyzer.full_analysis(
                    train_file,
                    use_sampling=config['use_sampling'],
                    num_groups=config.get('num_groups', Config.DEFAULT_NUM_GROUPS),
                    min_group_size=config.get('min_group_size', Config.DEFAULT_MIN_GROUP_SIZE)
                )
                train_results[f'segment_{i}'] = result
                
                # æ˜¾ç¤ºæœ€ä½³æ¨¡å‹
                if not result['model_results'].empty:
                    best_model = result['model_results'].loc[
                        result['model_results']['HitRate@3'].idxmax()
                    ]
                    print(f"âœ… æœ€ä½³æ¨¡å‹: {best_model['Model']} (HitRate@3: {best_model['HitRate@3']:.4f})")
                
            except Exception as e:
                print(f"âŒ è®­ç»ƒæ®µ {i} å¤±è´¥: {e}")
                continue
        
        # é¢„æµ‹é˜¶æ®µ (ä»…å®Œæ•´æµç¨‹)
        if run_mode == '1' and test_files:
            print(f"\n{'='*50}")
            print("é¢„æµ‹é˜¶æ®µ")
            print('='*50)
            
            # ä½¿ç”¨ä¿å­˜çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
            predictor = FlightRankingPredictor(Config.DATA_BASE_PATH)
            
            result = predictor.predict_all(
                segments=list(range(len(test_files))),
                model_names=config['selected_models'],
                ensemble_method='average'
            )
            
            if result is not None:
                print(f"âœ… é¢„æµ‹å®Œæˆï¼Œæ€»è®°å½•æ•°: {len(result)}")
            else:
                print("âŒ é¢„æµ‹å¤±è´¥")
        
        # æ˜¾ç¤ºè®­ç»ƒæ€»ç»“
        self._show_training_summary(train_results, config)
    
    def _show_training_summary(self, train_results: Dict[str, Any], config: Dict[str, Any]):
        """æ˜¾ç¤ºè®­ç»ƒæ€»ç»“"""
        print(f"\n{'='*60}")
        print("è®­ç»ƒæ€»ç»“")
        print('='*60)
        
        print(f"è®­ç»ƒæ®µæ•°: {len(train_results)}")
        print(f"ä½¿ç”¨æ¨¡å‹: {', '.join(config['selected_models'])}")
        
        # å„æ®µæœ€ä½³æ€§èƒ½
        if train_results:
            print(f"\nå„æ®µæœ€ä½³æ¨¡å‹æ€§èƒ½:")
            for segment_name, result in train_results.items():
                if 'model_results' in result and not result['model_results'].empty:
                    best_model = result['model_results'].loc[
                        result['model_results']['HitRate@3'].idxmax()
                    ]
                    model_type = "ğŸ”¥" if Config.is_pytorch_model(best_model['Model']) else "ğŸ“Š"
                    print(f"  {segment_name}: {best_model['Model']} {model_type} "
                          f"(HitRate@3: {best_model['HitRate@3']:.4f})")
        
        print(f"\nç»“æœä¿å­˜è·¯å¾„: {Config.OUTPUT_PATH}")


def main():
    """ä¸»å‡½æ•°"""
    # ç¡®ä¿é…ç½®æ­£ç¡®
    Config.ensure_paths()
    
    # è¿è¡Œå·¥ä½œæµ
    workflow = WorkflowManager()
    workflow.run()


if __name__ == "__main__":
    main()